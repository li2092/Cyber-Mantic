"""
æŠ¥å‘Šç”Ÿæˆå™¨æ¨¡å—

è´Ÿè´£ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Šï¼š
- ç»¼åˆåˆ†ææŠ¥å‘Š
- åˆ†ææ•°æ®æ‘˜è¦
- å›æº¯éªŒè¯æ‘˜è¦
- ç½®ä¿¡åº¦è®¡ç®—
- ç®€åŒ–ç‰ˆæŠ¥å‘Šï¼ˆé™çº§ï¼‰
"""

import json
from typing import Dict, Any, Optional, TYPE_CHECKING
from datetime import datetime

from utils.logger import get_logger
from core.timeline_analyzer import TimelineAnalyzer

if TYPE_CHECKING:
    from api.manager import APIManager
    from .context import ConversationContext


# æ—¶è¾°ä¸­æ–‡åç§°æ˜ å°„
HOUR_CHINESE_NAMES = {
    0: "å­", 1: "ä¸‘", 2: "ä¸‘", 3: "å¯…", 4: "å¯…", 5: "å¯",
    6: "å¯", 7: "è¾°", 8: "è¾°", 9: "å·³", 10: "å·³", 11: "åˆ",
    12: "åˆ", 13: "æœª", 14: "æœª", 15: "ç”³", 16: "ç”³", 17: "é…‰",
    18: "é…‰", 19: "æˆŒ", 20: "æˆŒ", 21: "äº¥", 22: "äº¥", 23: "å­"
}


class ReportGenerator:
    """
    æŠ¥å‘Šç”Ÿæˆå™¨

    è´Ÿè´£ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
    - è°ƒç”¨AIç”Ÿæˆç»¼åˆæŠ¥å‘Š
    - å‡†å¤‡å„ç†è®ºåˆ†ææ‘˜è¦
    - è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
    - é™çº§æŠ¥å‘Šç”Ÿæˆ
    """

    def __init__(
        self,
        api_manager: "APIManager",
        context: "ConversationContext"
    ):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            api_manager: APIç®¡ç†å™¨
            context: å¯¹è¯ä¸Šä¸‹æ–‡
        """
        self.api_manager = api_manager
        self.context = context
        self.logger = get_logger(__name__)
        self.timeline_analyzer = TimelineAnalyzer()  # åˆå§‹åŒ–æ—¶é—´çº¿åˆ†æå™¨

    async def generate_final_report(self) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆè¯¦ç»†æŠ¥å‘Šï¼ˆä½¿ç”¨AIç»¼åˆåˆ†æï¼‰

        Returns:
            å®Œæ•´çš„åˆ†ææŠ¥å‘Šæ–‡æœ¬
        """
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
        current_time_display = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")

        # å‡†å¤‡åˆ†ææ•°æ®æ‘˜è¦
        analysis_summary = self.prepare_analysis_summary()

        # å‡†å¤‡å›æº¯éªŒè¯æ‘˜è¦
        verification_summary = self.prepare_verification_summary()

        # è°ƒç”¨AIç”Ÿæˆç»¼åˆæŠ¥å‘Š
        prompt = self._build_report_prompt(
            current_time_display,
            analysis_summary,
            verification_summary
        )

        try:
            response = await self.api_manager.call_api(
                task_type="ç»¼åˆæŠ¥å‘Šè§£è¯»",  # ä½¿ç”¨Claudeè¿›è¡Œæ·±åº¦åˆ†æ
                prompt=prompt,
                enable_dual_verification=False
            )

            # ä¿å­˜ç»¼åˆåˆ†æ
            self.context.comprehensive_analysis = response

            # æ„å»ºå®Œæ•´æŠ¥å‘Š
            report_header = f"""# ğŸ”® èµ›åšç„æ•° - æ™ºèƒ½åˆ†ææŠ¥å‘Š

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

- **åˆ†ææ—¶é—´**ï¼š{current_time}
- **æ‰€é—®äº‹é¡¹**ï¼š{self.context.question_category} - {self.context.question_description}
- **ä½¿ç”¨ç†è®º**ï¼š{', '.join([t.get('theory', str(t)) if isinstance(t, dict) else str(t) for t in self.context.selected_theories])}
- **ç»¼åˆç½®ä¿¡åº¦**ï¼š{self.calculate_overall_confidence()}%

---

"""

            full_report = report_header + response

            return full_report.strip()

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
            # è¿”å›ç®€åŒ–ç‰ˆæŠ¥å‘Š
            return self.generate_simplified_report()

    # MBTIè¡¨è¾¾é£æ ¼æŒ‡å¯¼
    MBTI_EXPRESSION_STYLES = {
        # åˆ†æå‹ï¼ˆNTï¼‰- é‡é€»è¾‘ï¼Œå–œæ¬¢æ•°æ®å’ŒåŸç†
        "INTJ": {"é£æ ¼": "é€»è¾‘ä¸¥å¯†ã€æ•°æ®å¯¼å‘", "åå¥½": "ç³»ç»Ÿåˆ†æã€é•¿æœŸè§„åˆ’", "è¡¨è¾¾": "ç›´æ¥ç®€æ´ï¼Œé‡ç‚¹çªå‡ºå› æœå…³ç³»"},
        "INTP": {"é£æ ¼": "ç†è®ºæ·±å…¥ã€æ¢ç´¢åŸç†", "åå¥½": "åŸç†è§£é‡Šã€å¤šè§’åº¦åˆ†æ", "è¡¨è¾¾": "å¯ä»¥å±•å¼€ç†è®ºæ¨å¯¼ï¼Œä½†é¿å…ç©ºæ³›"},
        "ENTJ": {"é£æ ¼": "ç»“æœå¯¼å‘ã€å†³ç­–æ˜ç¡®", "åå¥½": "è¡ŒåŠ¨å»ºè®®ã€æ•ˆç‡ä¼˜å…ˆ", "è¡¨è¾¾": "å¼ºè°ƒå¯æ‰§è¡Œæ€§å’Œé¢„æœŸæ”¶ç›Š"},
        "ENTP": {"é£æ ¼": "çµæ´»å¤šå˜ã€å¯èƒ½æ€§å¯¼å‘", "åå¥½": "å¤šç§æ–¹æ¡ˆã€åˆ›æ„å»ºè®®", "è¡¨è¾¾": "å¯ä»¥æ¢è®¨å¤šç§å¯èƒ½ï¼Œä½†éœ€æœ‰ä¸»æ¬¡"},

        # å¤–äº¤å‹ï¼ˆNFï¼‰- é‡æ„Ÿå—ï¼Œå…³æ³¨æ„ä¹‰å’Œäººæ–‡
        "INFJ": {"é£æ ¼": "ç›´è§‰æ·±åˆ»ã€æ„ä¹‰å¯¼å‘", "åå¥½": "æ·±å±‚å«ä¹‰ã€äººç”Ÿæ„ä¹‰", "è¡¨è¾¾": "èå…¥å“²ç†æ€è€ƒï¼Œå…³æ³¨å†…å¿ƒæˆé•¿"},
        "INFP": {"é£æ ¼": "æ„Ÿæ€§ç»†è…»ã€ä»·å€¼å¯¼å‘", "åå¥½": "æƒ…æ„Ÿå…±é¸£ã€ä¸ªäººä»·å€¼", "è¡¨è¾¾": "æ¸©å’ŒåŒ…å®¹ï¼Œå…³æ³¨å†…å¿ƒæ„Ÿå—"},
        "ENFJ": {"é£æ ¼": "æ¸©æš–é¼“åŠ±ã€å…³ç³»å¯¼å‘", "åå¥½": "äººé™…å½±å“ã€åŠ©äººå»ºè®®", "è¡¨è¾¾": "ç§¯ææ­£é¢ï¼Œå…³æ³¨å¯¹ä»–äººçš„å½±å“"},
        "ENFP": {"é£æ ¼": "çƒ­æƒ…å¼€æ”¾ã€å¯èƒ½æ€§å¯¼å‘", "åå¥½": "çµæ„Ÿå¯å‘ã€æˆé•¿æœºä¼š", "è¡¨è¾¾": "å……æ»¡çƒ­æƒ…ï¼Œæ¢ç´¢æˆé•¿ç©ºé—´"},

        # å®ˆæŠ¤å‹ï¼ˆSJï¼‰- é‡ä¼ ç»Ÿï¼Œå–œæ¬¢å…·ä½“å’Œå¯é 
        "ISTJ": {"é£æ ¼": "åŠ¡å®ç¨³å¥ã€äº‹å®å¯¼å‘", "åå¥½": "å…·ä½“æ­¥éª¤ã€å¯é æ–¹æ³•", "è¡¨è¾¾": "æ¡ç†æ¸…æ™°ï¼Œæä¾›æ˜ç¡®æŒ‡å¼•"},
        "ISFJ": {"é£æ ¼": "ç»†å¿ƒå‘¨åˆ°ã€è´£ä»»å¯¼å‘", "åå¥½": "å®‰å…¨å»ºè®®ã€é£é™©æç¤º", "è¡¨è¾¾": "æ¸©å’Œç¨³é‡ï¼Œå…³æ³¨å®‰å…¨æ„Ÿ"},
        "ESTJ": {"é£æ ¼": "æ•ˆç‡åŠ¡å®ã€è¡ŒåŠ¨å¯¼å‘", "åå¥½": "æ˜ç¡®è®¡åˆ’ã€æ—¶é—´èŠ‚ç‚¹", "è¡¨è¾¾": "ç®€æ´æœ‰åŠ›ï¼Œå¼ºè°ƒè¡ŒåŠ¨æ­¥éª¤"},
        "ESFJ": {"é£æ ¼": "å…³æ€€å®é™…ã€å’Œè°å¯¼å‘", "åå¥½": "äººé™…å»ºè®®ã€æƒ…æ„Ÿæ”¯æŒ", "è¡¨è¾¾": "æ¸©æš–äº²åˆ‡ï¼Œå…³æ³¨äººé™…å…³ç³»"},

        # æ¢é™©å‹ï¼ˆSPï¼‰- é‡ä½“éªŒï¼Œå–œæ¬¢çµæ´»å’Œå½“ä¸‹
        "ISTP": {"é£æ ¼": "å†·é™åˆ†æã€å®ç”¨å¯¼å‘", "åå¥½": "æŠ€æœ¯åˆ†æã€å®æ“å»ºè®®", "è¡¨è¾¾": "ç®€æ´å®ç”¨ï¼Œç›´æŒ‡è¦ç‚¹"},
        "ISFP": {"é£æ ¼": "æ„Ÿæ€§ç›´è§‰ã€ä½“éªŒå¯¼å‘", "åå¥½": "æ„Ÿå—åˆ†äº«ã€çµæ´»å»ºè®®", "è¡¨è¾¾": "æ¸©å’Œè‡ªç„¶ï¼Œå°Šé‡ä¸ªäººæ„Ÿå—"},
        "ESTP": {"é£æ ¼": "ç›´æ¥æœæ–­ã€è¡ŒåŠ¨å¯¼å‘", "åå¥½": "å¿«é€Ÿå»ºè®®ã€å³æ—¶æ•ˆæœ", "è¡¨è¾¾": "ç®€çŸ­æœ‰åŠ›ï¼Œå¼ºè°ƒç«‹å³è¡ŒåŠ¨"},
        "ESFP": {"é£æ ¼": "ä¹è§‚ç§¯æã€ä½“éªŒå¯¼å‘", "åå¥½": "æœ‰è¶£å»ºè®®ã€æ­£é¢åé¦ˆ", "è¡¨è¾¾": "æ´»æ³¼ç§¯æï¼Œå¼ºè°ƒäº«å—è¿‡ç¨‹"},
    }

    def _build_report_prompt(
        self,
        current_time_display: str,
        analysis_summary: str,
        verification_summary: str
    ) -> str:
        """æ„å»ºæŠ¥å‘Šç”Ÿæˆçš„AI prompt"""
        # è·å–MBTIä¸ªæ€§åŒ–æŒ‡å¯¼
        mbti_style = self._get_mbti_style_guidance()

        # åŠ¨æ€ç”Ÿæˆæ—¶é—´çº¿promptï¼ˆæ ¹æ®ç”¨æˆ·é—®é¢˜ï¼‰
        timeline_prompt = self.timeline_analyzer.generate_timeline_prompt_section(
            question=self.context.question_description,
            question_type=self.context.question_category
        )

        return f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å‘½ç†åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„å‘½ç†åˆ†ææŠ¥å‘Šã€‚

ã€å½“å‰æ—¶é—´ã€‘ï¼š{current_time_display}
ï¼ˆæ³¨ï¼šæ—¶é—´ä»…ä¾›ä½ äº†è§£çœŸå®æ—¶åˆ»ï¼Œæ‰€æœ‰æ’ç›˜æ•°æ®å·²ç”±ç¨‹åºè®¡ç®—å®Œæˆï¼Œè¯·ç›´æ¥åˆ†æä¸‹æ–¹æ•°æ®ï¼Œä¸è¦è‡ªè¡Œé‡æ–°æ’ç›˜ï¼‰

## ç”¨æˆ·ä¿¡æ¯
- **é—®é¢˜ç±»åˆ«**ï¼š{self.context.question_category}
- **é—®é¢˜æè¿°**ï¼š{self.context.question_description}
- **å‡ºç”Ÿå¹´ä»½**ï¼š{self.context.birth_info.get('year') if self.context.birth_info else 'æœªçŸ¥'}å¹´
- **æ€§åˆ«**ï¼š{self.context.gender or 'æœªçŸ¥'}
- **MBTI**ï¼š{self.context.mbti_type or 'æœªçŸ¥'}

## ğŸ¯ MBTIä¸ªæ€§åŒ–è¡¨è¾¾æŒ‡å¯¼
{mbti_style}

## ä½¿ç”¨ç†è®º
{', '.join([t.get('theory', str(t)) if isinstance(t, dict) else str(t) for t in self.context.selected_theories])}

## åˆ†ææ•°æ®æ‘˜è¦
{analysis_summary}

## å›æº¯éªŒè¯ç»“æœ
{verification_summary}

---

è¯·ç”Ÿæˆä»¥ä¸‹æ ¼å¼çš„è¯¦ç»†æŠ¥å‘Šï¼ˆä¸¥æ ¼éµå¾ªmarkdownæ ¼å¼ï¼‰ï¼š

## ğŸ¯ æ ¸å¿ƒç»“è®ºï¼ˆ3å¥è¯ç‰ˆï¼‰

> 1. **æ€»ä½“åˆ¤æ–­**ï¼š[ä¸€å¥è¯æ€»ç»“å½“å‰çŠ¶æ€å’Œæ€»ä½“è¶‹åŠ¿ï¼Œ50å­—ä»¥å†…]
> 2. **å…³é”®æ—¶æœº**ï¼š[æŒ‡å‡ºæœ€ä½³æ—¶é—´çª—å£æˆ–éœ€è¦æ³¨æ„çš„æ—¶é—´èŠ‚ç‚¹ï¼Œ50å­—ä»¥å†…]
> 3. **é¦–è¦å»ºè®®**ï¼š[æœ€æ ¸å¿ƒçš„ä¸€æ¡è¡ŒåŠ¨å»ºè®®ï¼Œ50å­—ä»¥å†…]

## ğŸ“Š å¤šç†è®ºåˆ†ææ‘˜è¦

[é’ˆå¯¹æ¯ä¸ªä½¿ç”¨çš„ç†è®ºï¼Œåˆ†åˆ«è¯´æ˜æ ¸å¿ƒç»“è®ºå’Œå…³é”®å‘ç°ï¼Œæ¯ä¸ªç†è®º100-150å­—]

{timeline_prompt}

## ğŸ§­ è¡ŒåŠ¨å»ºè®®

### ğŸ”¥ é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³è¡ŒåŠ¨ï¼‰
1. **[é¢†åŸŸ]**ï¼š[å…·ä½“å»ºè®®ï¼ŒåŒ…æ‹¬æ—¶é—´ã€æ–¹å¼ã€é¢„æœŸæ•ˆæœ]
2. **[é¢†åŸŸ]**ï¼š[å…·ä½“å»ºè®®]

### ğŸ“Œ ä¸­ä¼˜å…ˆçº§ï¼ˆè¿‘æœŸè€ƒè™‘ï¼‰
1. **[é¢†åŸŸ]**ï¼š[å…·ä½“å»ºè®®]
2. **[é¢†åŸŸ]**ï¼š[å…·ä½“å»ºè®®]

### ğŸ’¡ MBTIäººæ ¼é€‚é…å»ºè®®
[æ ¹æ®ç”¨æˆ·çš„MBTIç±»å‹ï¼Œç»™å‡ºä¸ªæ€§åŒ–çš„æ²Ÿé€šæ–¹å¼ã€å†³ç­–å»ºè®®ã€æ³¨æ„äº‹é¡¹]

---

**é‡è¦è¯´æ˜**ï¼š
1. æ‰€æœ‰é¢„æµ‹ä»…ä¾›å‚è€ƒï¼Œæœ€ç»ˆå†³å®šæƒåœ¨æ‚¨æ‰‹ä¸­
2. å‘½ç†åˆ†ææ˜¯ä¸€ç§æ€ç»´å·¥å…·ï¼Œå¸®åŠ©æ‚¨æ›´å¥½åœ°è®¤è¯†è‡ªå·±
3. å»ºè®®ç»“åˆå®é™…æƒ…å†µçµæ´»è¿ç”¨

ğŸ’¬ **å¦‚æœ‰ç–‘é—®ï¼Œæ¬¢è¿ç»§ç»­æé—®ï¼**
"""

    def prepare_analysis_summary(self) -> str:
        """
        å‡†å¤‡åˆ†ææ•°æ®æ‘˜è¦

        Returns:
            åˆ†ææ‘˜è¦æ–‡æœ¬
        """
        summary = ""

        # å°å…­å£¬ç»“æœ
        if self.context.xiaoliu_result:
            xiaoliu_summary = f"""
**å°å…­å£¬å¿«åˆ¤**ï¼š
- å‰å‡¶ï¼š{self.context.xiaoliu_result.get('å‰å‡¶åˆ¤æ–­', 'æœªçŸ¥')}
- æ—¶è½å®«ï¼š{self.context.xiaoliu_result.get('æ—¶è½å®«', 'æœªçŸ¥')}
"""
            summary += xiaoliu_summary

        # å…«å­—ç»“æœ
        if self.context.bazi_result:
            # å››æŸ±æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œä½¿ç”¨å•ç‹¬çš„å¹´æŸ±/æœˆæŸ±/æ—¥æŸ±/æ—¶æŸ±å­—å…¸
            year_pillar = self.context.bazi_result.get('å¹´æŸ±', {}) or {}
            month_pillar = self.context.bazi_result.get('æœˆæŸ±', {}) or {}
            day_pillar = self.context.bazi_result.get('æ—¥æŸ±', {}) or {}
            hour_pillar = self.context.bazi_result.get('æ—¶æŸ±', {}) or {}
            bazi_summary = f"""
**å…«å­—å‘½ç›˜**ï¼š
- å¹´æŸ±ï¼š{year_pillar.get('å¤©å¹²', '')}{year_pillar.get('åœ°æ”¯', '')}
- æœˆæŸ±ï¼š{month_pillar.get('å¤©å¹²', '')}{month_pillar.get('åœ°æ”¯', '')}
- æ—¥æŸ±ï¼š{day_pillar.get('å¤©å¹²', '')}{day_pillar.get('åœ°æ”¯', '')}
- æ—¶æŸ±ï¼š{hour_pillar.get('å¤©å¹²', '')}{hour_pillar.get('åœ°æ”¯', '')}
- æ—¥ä¸»ï¼š{self.context.bazi_result.get('æ—¥ä¸»', 'æœªçŸ¥')}
"""
            summary += bazi_summary

        # å¥‡é—¨éç”²ç»“æœ
        if self.context.qimen_result:
            qimen_summary = f"""
**å¥‡é—¨éç”²**ï¼š
- å€¼ç¬¦ï¼š{self.context.qimen_result.get('å€¼ç¬¦', 'æœªçŸ¥')}
- ç”¨ç¥å®«ä½ï¼š{self.context.qimen_result.get('ç”¨ç¥å®«ä½', 'æœªçŸ¥')}
- æ ¼å±€ï¼š{self.context.qimen_result.get('æ ¼å±€', 'æœªçŸ¥')}
"""
            summary += qimen_summary

        # å¤§å…­å£¬ç»“æœ
        if self.context.liuren_result:
            liuren_summary = f"""
**å¤§å…­å£¬**ï¼š
- è¯¾ä½“ï¼š{self.context.liuren_result.get('è¯¾ä½“', 'æœªçŸ¥')}
- ä¸‰ä¼ ï¼š{self.context.liuren_result.get('ä¸‰ä¼ ', 'æœªçŸ¥')}
- å‰å‡¶ï¼š{self.context.liuren_result.get('å‰å‡¶', 'æœªçŸ¥')}
"""
            summary += liuren_summary

        # å…­çˆ»ç»“æœ
        if self.context.liuyao_result:
            ben_gua = self.context.liuyao_result.get('æœ¬å¦', {})
            bian_gua = self.context.liuyao_result.get('å˜å¦')
            liuyao_summary = f"""
**å…­çˆ»**ï¼š
- æœ¬å¦ï¼š{ben_gua.get('å¦å', 'æœªçŸ¥') if isinstance(ben_gua, dict) else 'æœªçŸ¥'}
- å˜å¦ï¼š{bian_gua.get('å¦å', 'æœªçŸ¥') if isinstance(bian_gua, dict) and bian_gua else 'æ— '}
- ç”¨ç¥ï¼š{self.context.liuyao_result.get('ç”¨ç¥', 'æœªçŸ¥')}
"""
            summary += liuyao_summary

        # æ¢…èŠ±æ˜“æ•°ç»“æœ
        if self.context.meihua_result:
            meihua_summary = f"""
**æ¢…èŠ±æ˜“æ•°**ï¼š
- ä¸»å¦ï¼š{self.context.meihua_result.get('ä¸»å¦', {}).get('å¦å', 'æœªçŸ¥')}
- å˜å¦ï¼š{self.context.meihua_result.get('å˜å¦', {}).get('å¦å', 'æœªçŸ¥')}
- äº’å¦ï¼š{self.context.meihua_result.get('äº’å¦', {}).get('å¦å', 'æœªçŸ¥')}
"""
            summary += meihua_summary

        # æ—¶è¾°æ¨æ–­ä¿¡æ¯
        if self.context.time_certainty == "inferred":
            hour_name = self._hour_to_chinese(self.context.inferred_hour)
            summary += f"\n**æ—¶è¾°æ¨æ–­**ï¼šæ ¹æ®è¡¥å……ä¿¡æ¯æ¨æ–­ä¸º{hour_name}æ—¶ï¼ˆç½®ä¿¡åº¦70%ï¼‰\n"

        return summary if summary else "ï¼ˆæ— è¯¦ç»†åˆ†ææ•°æ®ï¼‰"

    def prepare_verification_summary(self) -> str:
        """
        å‡†å¤‡å›æº¯éªŒè¯æ‘˜è¦

        Returns:
            éªŒè¯æ‘˜è¦æ–‡æœ¬
        """
        if not self.context.verification_feedback:
            return "ï¼ˆç”¨æˆ·æœªæä¾›å›æº¯éªŒè¯åé¦ˆï¼‰"

        latest_feedback = self.context.verification_feedback[-1]
        parsed = latest_feedback.get("parsed_feedback", {})

        match_count = parsed.get("match_count", 0)
        total_count = parsed.get("total_count", 0)

        if total_count > 0:
            accuracy = (match_count / total_count) * 100
            return f"""
**å›æº¯éªŒè¯å‡†ç¡®ç‡**ï¼š{accuracy:.0f}% ({match_count}/{total_count}ä¸ªäº‹ä»¶ç¬¦åˆ)

éªŒè¯è¯¦æƒ…ï¼š
{json.dumps(parsed.get('matches', []), ensure_ascii=False, indent=2)[:300]}
"""
        else:
            return "ï¼ˆæ— å›æº¯éªŒè¯æ•°æ®ï¼‰"

    def calculate_overall_confidence(self) -> int:
        """
        è®¡ç®—ç»¼åˆç½®ä¿¡åº¦

        Returns:
            ç½®ä¿¡åº¦ç™¾åˆ†æ¯” (0-100)
        """
        base_confidence = 75  # åŸºç¡€ç½®ä¿¡åº¦

        # æ ¹æ®ç†è®ºæ•°é‡è°ƒæ•´
        theory_count = len(self.context.selected_theories)
        if theory_count >= 3:
            base_confidence += 10
        elif theory_count >= 2:
            base_confidence += 5

        # æ ¹æ®å›æº¯éªŒè¯è°ƒæ•´
        if self.context.verification_feedback:
            latest_feedback = self.context.verification_feedback[-1]
            parsed = latest_feedback.get("parsed_feedback", {})
            match_count = parsed.get("match_count", 0)
            total_count = parsed.get("total_count", 1)
            accuracy = match_count / total_count

            if accuracy >= 0.8:
                base_confidence += 10
            elif accuracy >= 0.5:
                base_confidence += 5
            else:
                base_confidence -= 10

        # æ ¹æ®æ—¶è¾°ç¡®å®šæ€§è°ƒæ•´
        if self.context.time_certainty == "certain":
            base_confidence += 5
        elif self.context.time_certainty == "inferred":
            base_confidence -= 5

        # é™åˆ¶åœ¨0-100èŒƒå›´å†…
        return max(0, min(100, base_confidence))

    def generate_simplified_report(self) -> str:
        """
        ç”Ÿæˆç®€åŒ–ç‰ˆæŠ¥å‘Šï¼ˆAIè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨ï¼‰

        Returns:
            ç®€åŒ–ç‰ˆæŠ¥å‘Šæ–‡æœ¬
        """
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M")

        return f"""# ğŸ”® èµ›åšç„æ•° - æ™ºèƒ½åˆ†ææŠ¥å‘Š

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

- **åˆ†ææ—¶é—´**ï¼š{current_time}
- **æ‰€é—®äº‹é¡¹**ï¼š{self.context.question_category} - {self.context.question_description}
- **ä½¿ç”¨ç†è®º**ï¼š{', '.join([t.get('theory', str(t)) if isinstance(t, dict) else str(t) for t in self.context.selected_theories])}
- **ç»¼åˆç½®ä¿¡åº¦**ï¼š{self.calculate_overall_confidence()}%

---

## ğŸ¯ æ ¸å¿ƒç»“è®º

åŸºäº{', '.join([t.get('theory', str(t)) if isinstance(t, dict) else str(t) for t in self.context.selected_theories])}çš„ç»¼åˆåˆ†æï¼Œæˆ‘ä»¬ä¸ºæ‚¨æä¾›äº†ä»¥ä¸‹å‚è€ƒå»ºè®®ã€‚

## ğŸ“Š åˆ†ææ‘˜è¦

{self.prepare_analysis_summary()}

## âª å›æº¯éªŒè¯

{self.prepare_verification_summary()}

---

ğŸ’¬ **å¦‚æœ‰ç–‘é—®ï¼Œæ¬¢è¿ç»§ç»­æé—®ï¼æˆ‘ä¼šä¸ºæ‚¨è¯¦ç»†è§£ç­”ã€‚**

**æ³¨æ„**ï¼šç”±äºç³»ç»Ÿç¹å¿™ï¼Œè¯¦ç»†æŠ¥å‘Šç”Ÿæˆå¤±è´¥ã€‚æ‚¨å¯ä»¥é’ˆå¯¹å…·ä½“é—®é¢˜ç»§ç»­æé—®ï¼Œæˆ‘ä¼šä¸ºæ‚¨è¯¦ç»†è§£ç­”ã€‚
"""

    def _hour_to_chinese(self, hour: Optional[int]) -> str:
        """
        å°†å°æ—¶è½¬æ¢ä¸ºä¸­æ–‡æ—¶è¾°å

        Args:
            hour: å°æ—¶æ•° (0-23)

        Returns:
            ä¸­æ–‡æ—¶è¾°å
        """
        if hour is None:
            return "æœªçŸ¥"
        return HOUR_CHINESE_NAMES.get(hour, "æœªçŸ¥")

    def _get_mbti_style_guidance(self) -> str:
        """
        è·å–MBTIä¸ªæ€§åŒ–è¡¨è¾¾æŒ‡å¯¼

        Returns:
            è¡¨è¾¾é£æ ¼æŒ‡å¯¼æ–‡æœ¬
        """
        mbti_type = self.context.mbti_type
        if not mbti_type:
            return "ç”¨æˆ·æœªæä¾›MBTIï¼Œä½¿ç”¨æ ‡å‡†è¡¨è¾¾é£æ ¼ï¼Œè¯­æ°”ä¸“ä¸šä¸­æ€§ã€‚"

        mbti_type = mbti_type.upper()
        style_info = self.MBTI_EXPRESSION_STYLES.get(mbti_type)

        if not style_info:
            return f"ç”¨æˆ·MBTIç±»å‹ï¼ˆ{mbti_type}ï¼‰æœªçŸ¥ï¼Œä½¿ç”¨æ ‡å‡†è¡¨è¾¾é£æ ¼ã€‚"

        return f"""ç”¨æˆ·æ˜¯**{mbti_type}**ç±»å‹ï¼Œè¯·æŒ‰ä»¥ä¸‹é£æ ¼è°ƒæ•´æŠ¥å‘Šè¡¨è¾¾ï¼š
- **æ²Ÿé€šé£æ ¼**ï¼š{style_info['é£æ ¼']}
- **å†…å®¹åå¥½**ï¼š{style_info['åå¥½']}
- **è¡¨è¾¾æ–¹å¼**ï¼š{style_info['è¡¨è¾¾']}

**é‡è¦**ï¼šè¯·æ ¹æ®ä»¥ä¸ŠMBTIç‰¹ç‚¹è°ƒæ•´æŠ¥å‘Šçš„è¯­æ°”ã€å†…å®¹ä¾§é‡ç‚¹å’Œå»ºè®®æ–¹å¼ï¼Œä½¿æŠ¥å‘Šæ›´è´´åˆç”¨æˆ·çš„è®¤çŸ¥åå¥½ã€‚"""


class ConversationExporter:
    """
    å¯¹è¯å¯¼å‡ºå™¨

    è´Ÿè´£å°†å¯¹è¯å†…å®¹å¯¼å‡ºä¸ºå„ç§æ ¼å¼
    """

    def __init__(self, context: "ConversationContext"):
        """
        åˆå§‹åŒ–å¯¼å‡ºå™¨

        Args:
            context: å¯¹è¯ä¸Šä¸‹æ–‡
        """
        self.context = context

    def export_to_markdown(self) -> str:
        """
        å°†å¯¹è¯å¯¼å‡ºä¸ºMarkdownæ ¼å¼

        Returns:
            Markdownæ ¼å¼çš„å¯¹è¯å†…å®¹
        """
        md_content = f"""# èµ›åšç„æ•° - å¯¹è¯è®°å½•

**å¯¼å‡ºæ—¶é—´**ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**å¯¹è¯é˜¶æ®µ**ï¼š{self.context.stage.value}

---

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

**é—®é¢˜ç±»åˆ«**ï¼š{self.context.question_category or 'æœªå¡«å†™'}
**é—®é¢˜æè¿°**ï¼š{self.context.question_description or 'æœªå¡«å†™'}

**å‡ºç”Ÿä¿¡æ¯**ï¼š
"""

        if self.context.birth_info:
            birth = self.context.birth_info
            md_content += f"""- å¹´ä»½ï¼š{birth.get('year')}å¹´
- æœˆä»½ï¼š{birth.get('month')}æœˆ
- æ—¥æœŸï¼š{birth.get('day')}æ—¥
- æ—¶è¾°ï¼š{birth.get('hour', 'æœªçŸ¥')}æ—¶
- å†æ³•ï¼š{'å†œå†' if birth.get('calendar_type') == 'lunar' else 'é˜³å†'}
- æ—¶è¾°ç¡®å®šæ€§ï¼š{self.context.time_certainty}
"""
        else:
            md_content += "- æœªå¡«å†™\n"

        md_content += f"""
**å…¶ä»–ä¿¡æ¯**ï¼š
- æ€§åˆ«ï¼š{self.context.gender or 'æœªå¡«å†™'}
- MBTIï¼š{self.context.mbti_type or 'æœªå¡«å†™'}

---

## ğŸ”® åˆ†ææ¦‚å†µ

**ä½¿ç”¨ç†è®º**ï¼š{', '.join([t.get('theory', str(t)) if isinstance(t, dict) else str(t) for t in self.context.selected_theories]) if self.context.selected_theories else 'æœªé€‰æ‹©'}

**åˆ†æçŠ¶æ€**ï¼š
- å°å…­å£¬ï¼š{'âœ“ å·²åˆ†æ' if self.context.xiaoliu_result else 'âœ— æœªåˆ†æ'}
- å…«å­—ï¼š{'âœ“ å·²åˆ†æ' if self.context.bazi_result else 'âœ— æœªåˆ†æ'}
- å¥‡é—¨éç”²ï¼š{'âœ“ å·²åˆ†æ' if self.context.qimen_result else 'âœ— æœªåˆ†æ'}
- å¤§å…­å£¬ï¼š{'âœ“ å·²åˆ†æ' if self.context.liuren_result else 'âœ— æœªåˆ†æ'}
- å…­çˆ»ï¼š{'âœ“ å·²åˆ†æ' if self.context.liuyao_result else 'âœ— æœªåˆ†æ'}
- æ¢…èŠ±æ˜“æ•°ï¼š{'âœ“ å·²åˆ†æ' if self.context.meihua_result else 'âœ— æœªåˆ†æ'}

---

## ğŸ’¬ å¯¹è¯å†å²

"""

        # æ·»åŠ å¯¹è¯å†å²
        for msg in self.context.conversation_history:
            role = "ğŸ‘¤ **ç”¨æˆ·**" if msg.get("role") == "user" else "ğŸ¤– **åŠ©æ‰‹**"
            content = msg.get("content", "")
            md_content += f"{role}ï¼š\n\n{content}\n\n---\n\n"

        if self.context.comprehensive_analysis:
            md_content += f"""## ğŸ“Š ç»¼åˆåˆ†ææŠ¥å‘Š

{self.context.comprehensive_analysis}

---
"""

        md_content += """
*æœ¬æŠ¥å‘Šç”±èµ›åšç„æ•°AIç³»ç»Ÿç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*
"""

        return md_content

    def to_save_dict(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆç”¨äºä¿å­˜çš„å­—å…¸

        Returns:
            åŒ…å«å®Œæ•´å¯¹è¯æ•°æ®çš„å­—å…¸
        """
        return {
            "timestamp": datetime.now().isoformat(),
            "session_id": id(self.context),
            "context": self.context.to_dict(),
            "full_conversation": self.context.conversation_history,
            "summary": self.get_summary(),
            "statistics": self.get_statistics()
        }

    def get_summary(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¯¹è¯æ‘˜è¦

        Returns:
            å¯¹è¯æ‘˜è¦å­—å…¸
        """
        return {
            "stage": self.context.stage.value,
            "question": {
                "category": self.context.question_category,
                "description": self.context.question_description[:100] + "..."
                if len(self.context.question_description) > 100
                else self.context.question_description
            },
            "user_info": {
                "birth_year": self.context.birth_info.get("year") if self.context.birth_info else None,
                "gender": self.context.gender,
                "mbti": self.context.mbti_type,
                "time_certainty": self.context.time_certainty
            },
            "analysis_status": {
                "theories_used": self.context.selected_theories,
                "bazi_analyzed": self.context.bazi_result is not None,
                "qimen_analyzed": self.context.qimen_result is not None,
                "liuren_analyzed": self.context.liuren_result is not None,
                "report_generated": bool(self.context.comprehensive_analysis)
            },
            "verification": {
                "retrospective_events_count": len(self.context.retrospective_events),
                "feedback_provided": len(self.context.verification_feedback) > 0,
                "confidence_adjusted": bool(self.context.theory_confidence_adjustment)
            }
        }

    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return {
            "total_messages": len(self.context.conversation_history),
            "user_messages": len([m for m in self.context.conversation_history if m.get("role") == "user"]),
            "assistant_messages": len([m for m in self.context.conversation_history if m.get("role") == "assistant"]),
            "theories_count": len(self.context.selected_theories),
            "has_xiaoliu": self.context.xiaoliu_result is not None,
            "has_bazi": self.context.bazi_result is not None,
            "has_report": bool(self.context.comprehensive_analysis)
        }
