"""
æŠ¥å‘Šç”Ÿæˆå™¨æ¨¡å—

è´Ÿè´£ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Šï¼š
- ç»¼åˆåˆ†ææŠ¥å‘Š
- åˆ†ææ•°æ®æ‘˜è¦
- å›æº¯éªŒè¯æ‘˜è¦
- ç½®ä¿¡åº¦è®¡ç®—
- ç®€åŒ–ç‰ˆæŠ¥å‘Šï¼ˆé™çº§ï¼‰
"""

import json
from typing import Dict, Any, Optional, TYPE_CHECKING
from datetime import datetime

from utils.logger import get_logger

if TYPE_CHECKING:
    from api.manager import APIManager
    from .context import ConversationContext


# æ—¶è¾°ä¸­æ–‡åç§°æ˜ å°„
HOUR_CHINESE_NAMES = {
    0: "å­", 1: "ä¸‘", 2: "ä¸‘", 3: "å¯…", 4: "å¯…", 5: "å¯",
    6: "å¯", 7: "è¾°", 8: "è¾°", 9: "å·³", 10: "å·³", 11: "åˆ",
    12: "åˆ", 13: "æœª", 14: "æœª", 15: "ç”³", 16: "ç”³", 17: "é…‰",
    18: "é…‰", 19: "æˆŒ", 20: "æˆŒ", 21: "äº¥", 22: "äº¥", 23: "å­"
}


class ReportGenerator:
    """
    æŠ¥å‘Šç”Ÿæˆå™¨

    è´Ÿè´£ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
    - è°ƒç”¨AIç”Ÿæˆç»¼åˆæŠ¥å‘Š
    - å‡†å¤‡å„ç†è®ºåˆ†ææ‘˜è¦
    - è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
    - é™çº§æŠ¥å‘Šç”Ÿæˆ
    """

    def __init__(
        self,
        api_manager: "APIManager",
        context: "ConversationContext"
    ):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            api_manager: APIç®¡ç†å™¨
            context: å¯¹è¯ä¸Šä¸‹æ–‡
        """
        self.api_manager = api_manager
        self.context = context
        self.logger = get_logger(__name__)

    async def generate_final_report(self) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆè¯¦ç»†æŠ¥å‘Šï¼ˆä½¿ç”¨AIç»¼åˆåˆ†æï¼‰

        Returns:
            å®Œæ•´çš„åˆ†ææŠ¥å‘Šæ–‡æœ¬
        """
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
        current_time_display = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")

        # å‡†å¤‡åˆ†ææ•°æ®æ‘˜è¦
        analysis_summary = self.prepare_analysis_summary()

        # å‡†å¤‡å›æº¯éªŒè¯æ‘˜è¦
        verification_summary = self.prepare_verification_summary()

        # è°ƒç”¨AIç”Ÿæˆç»¼åˆæŠ¥å‘Š
        prompt = self._build_report_prompt(
            current_time_display,
            analysis_summary,
            verification_summary
        )

        try:
            response = await self.api_manager.call_api(
                task_type="ç»¼åˆæŠ¥å‘Šè§£è¯»",  # ä½¿ç”¨Claudeè¿›è¡Œæ·±åº¦åˆ†æ
                prompt=prompt,
                enable_dual_verification=False
            )

            # ä¿å­˜ç»¼åˆåˆ†æ
            self.context.comprehensive_analysis = response

            # æ„å»ºå®Œæ•´æŠ¥å‘Š
            report_header = f"""# ğŸ”® èµ›åšç„æ•° - æ™ºèƒ½åˆ†ææŠ¥å‘Š

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

- **åˆ†ææ—¶é—´**ï¼š{current_time}
- **æ‰€é—®äº‹é¡¹**ï¼š{self.context.question_category} - {self.context.question_description}
- **ä½¿ç”¨ç†è®º**ï¼š{', '.join(self.context.selected_theories)}
- **ç»¼åˆç½®ä¿¡åº¦**ï¼š{self.calculate_overall_confidence()}%

---

"""

            full_report = report_header + response

            return full_report.strip()

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
            # è¿”å›ç®€åŒ–ç‰ˆæŠ¥å‘Š
            return self.generate_simplified_report()

    def _build_report_prompt(
        self,
        current_time_display: str,
        analysis_summary: str,
        verification_summary: str
    ) -> str:
        """æ„å»ºæŠ¥å‘Šç”Ÿæˆçš„AI prompt"""
        return f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å‘½ç†åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„å‘½ç†åˆ†ææŠ¥å‘Šã€‚

ã€å½“å‰æ—¶é—´ã€‘ï¼š{current_time_display}
ï¼ˆæ³¨ï¼šæ—¶é—´ä»…ä¾›ä½ äº†è§£çœŸå®æ—¶åˆ»ï¼Œæ‰€æœ‰æ’ç›˜æ•°æ®å·²ç”±ç¨‹åºè®¡ç®—å®Œæˆï¼Œè¯·ç›´æ¥åˆ†æä¸‹æ–¹æ•°æ®ï¼Œä¸è¦è‡ªè¡Œé‡æ–°æ’ç›˜ï¼‰

## ç”¨æˆ·ä¿¡æ¯
- **é—®é¢˜ç±»åˆ«**ï¼š{self.context.question_category}
- **é—®é¢˜æè¿°**ï¼š{self.context.question_description}
- **å‡ºç”Ÿå¹´ä»½**ï¼š{self.context.birth_info.get('year') if self.context.birth_info else 'æœªçŸ¥'}å¹´
- **æ€§åˆ«**ï¼š{self.context.gender or 'æœªçŸ¥'}
- **MBTI**ï¼š{self.context.mbti_type or 'æœªçŸ¥'}

## ä½¿ç”¨ç†è®º
{', '.join(self.context.selected_theories)}

## åˆ†ææ•°æ®æ‘˜è¦
{analysis_summary}

## å›æº¯éªŒè¯ç»“æœ
{verification_summary}

---

è¯·ç”Ÿæˆä»¥ä¸‹æ ¼å¼çš„è¯¦ç»†æŠ¥å‘Šï¼ˆä¸¥æ ¼éµå¾ªmarkdownæ ¼å¼ï¼‰ï¼š

## ğŸ¯ æ ¸å¿ƒç»“è®ºï¼ˆ3å¥è¯ç‰ˆï¼‰

> 1. **æ€»ä½“åˆ¤æ–­**ï¼š[ä¸€å¥è¯æ€»ç»“å½“å‰çŠ¶æ€å’Œæ€»ä½“è¶‹åŠ¿ï¼Œ50å­—ä»¥å†…]
> 2. **å…³é”®æ—¶æœº**ï¼š[æŒ‡å‡ºæœ€ä½³æ—¶é—´çª—å£æˆ–éœ€è¦æ³¨æ„çš„æ—¶é—´èŠ‚ç‚¹ï¼Œ50å­—ä»¥å†…]
> 3. **é¦–è¦å»ºè®®**ï¼š[æœ€æ ¸å¿ƒçš„ä¸€æ¡è¡ŒåŠ¨å»ºè®®ï¼Œ50å­—ä»¥å†…]

## ğŸ“Š å¤šç†è®ºåˆ†ææ‘˜è¦

[é’ˆå¯¹æ¯ä¸ªä½¿ç”¨çš„ç†è®ºï¼Œåˆ†åˆ«è¯´æ˜æ ¸å¿ƒç»“è®ºå’Œå…³é”®å‘ç°ï¼Œæ¯ä¸ªç†è®º100-150å­—]

## ğŸ”® é¢„æµ‹åˆ†æï¼ˆæ—¶é—´çº¿è§†å›¾ï¼‰

### è¿‘æœŸï¼ˆ1-3ä¸ªæœˆï¼‰
- **æ•´ä½“è¶‹åŠ¿**ï¼š[æè¿°]
- **å…³é”®èŠ‚ç‚¹**ï¼š[å…·ä½“æ—¥æœŸæˆ–æ—¶é—´æ®µ] - [å¯èƒ½äº‹ä»¶]
- **æ³¨æ„äº‹é¡¹**ï¼š[æé†’]

### ä¸­æœŸï¼ˆ3-12ä¸ªæœˆï¼‰
- **æ•´ä½“è¶‹åŠ¿**ï¼š[æè¿°]
- **æœºä¼šçª—å£**ï¼š[æ—¶é—´æ®µ] - [å»ºè®®è¡ŒåŠ¨]
- **é£é™©æç¤º**ï¼š[éœ€è¦æ³¨æ„çš„é—®é¢˜]

## ğŸ§­ è¡ŒåŠ¨å»ºè®®

### ğŸ”¥ é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³è¡ŒåŠ¨ï¼‰
1. **[é¢†åŸŸ]**ï¼š[å…·ä½“å»ºè®®ï¼ŒåŒ…æ‹¬æ—¶é—´ã€æ–¹å¼ã€é¢„æœŸæ•ˆæœ]
2. **[é¢†åŸŸ]**ï¼š[å…·ä½“å»ºè®®]

### ğŸ“Œ ä¸­ä¼˜å…ˆçº§ï¼ˆè¿‘æœŸè€ƒè™‘ï¼‰
1. **[é¢†åŸŸ]**ï¼š[å…·ä½“å»ºè®®]
2. **[é¢†åŸŸ]**ï¼š[å…·ä½“å»ºè®®]

### ğŸ’¡ MBTIäººæ ¼é€‚é…å»ºè®®
[æ ¹æ®ç”¨æˆ·çš„MBTIç±»å‹ï¼Œç»™å‡ºä¸ªæ€§åŒ–çš„æ²Ÿé€šæ–¹å¼ã€å†³ç­–å»ºè®®ã€æ³¨æ„äº‹é¡¹]

---

**é‡è¦è¯´æ˜**ï¼š
1. æ‰€æœ‰é¢„æµ‹ä»…ä¾›å‚è€ƒï¼Œæœ€ç»ˆå†³å®šæƒåœ¨æ‚¨æ‰‹ä¸­
2. å‘½ç†åˆ†ææ˜¯ä¸€ç§æ€ç»´å·¥å…·ï¼Œå¸®åŠ©æ‚¨æ›´å¥½åœ°è®¤è¯†è‡ªå·±
3. å»ºè®®ç»“åˆå®é™…æƒ…å†µçµæ´»è¿ç”¨

ğŸ’¬ **å¦‚æœ‰ç–‘é—®ï¼Œæ¬¢è¿ç»§ç»­æé—®ï¼**
"""

    def prepare_analysis_summary(self) -> str:
        """
        å‡†å¤‡åˆ†ææ•°æ®æ‘˜è¦

        Returns:
            åˆ†ææ‘˜è¦æ–‡æœ¬
        """
        summary = ""

        # å°å…­å£¬ç»“æœ
        if self.context.xiaoliu_result:
            xiaoliu_result = self.context.xiaoliu_result
            judgment = xiaoliu_result.get('judgment', xiaoliu_result.get('å‰å‡¶åˆ¤æ–­', 'æœªçŸ¥'))
            position = xiaoliu_result.get('æ—¶è½å®«', xiaoliu_result.get('æœ€ç»ˆè½å®«', 'æœªçŸ¥'))
            xiaoliu_summary = f"""
**å°å…­å£¬å¿«åˆ¤**ï¼š
- å‰å‡¶ï¼š{judgment}
- æ—¶è½å®«ï¼š{position}
"""
            summary += xiaoliu_summary

        # å…«å­—ç»“æœ
        if self.context.bazi_result:
            # å››æŸ±æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œä½¿ç”¨å•ç‹¬çš„å¹´æŸ±/æœˆæŸ±/æ—¥æŸ±/æ—¶æŸ±å­—å…¸
            year_pillar = self.context.bazi_result.get('å¹´æŸ±', {}) or {}
            month_pillar = self.context.bazi_result.get('æœˆæŸ±', {}) or {}
            day_pillar = self.context.bazi_result.get('æ—¥æŸ±', {}) or {}
            hour_pillar = self.context.bazi_result.get('æ—¶æŸ±', {}) or {}
            bazi_summary = f"""
**å…«å­—å‘½ç›˜**ï¼š
- å¹´æŸ±ï¼š{year_pillar.get('å¤©å¹²', '')}{year_pillar.get('åœ°æ”¯', '')}
- æœˆæŸ±ï¼š{month_pillar.get('å¤©å¹²', '')}{month_pillar.get('åœ°æ”¯', '')}
- æ—¥æŸ±ï¼š{day_pillar.get('å¤©å¹²', '')}{day_pillar.get('åœ°æ”¯', '')}
- æ—¶æŸ±ï¼š{hour_pillar.get('å¤©å¹²', '')}{hour_pillar.get('åœ°æ”¯', '')}
- æ—¥ä¸»ï¼š{self.context.bazi_result.get('æ—¥ä¸»', 'æœªçŸ¥')}
"""
            summary += bazi_summary

        # å¥‡é—¨éç”²ç»“æœ
        if self.context.qimen_result:
            # æ ¼å±€æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œéœ€è¦æ ¼å¼åŒ–
            patterns = self.context.qimen_result.get('æ ¼å±€', [])
            pattern_str = 'ã€'.join([p.get('æ ¼å±€', '') for p in patterns]) if patterns else 'æœªçŸ¥'
            qimen_summary = f"""
**å¥‡é—¨éç”²**ï¼š
- å€¼ç¬¦å®«ï¼š{self.context.qimen_result.get('å€¼ç¬¦å®«', 'æœªçŸ¥')}
- ç”¨ç¥å®«ä½ï¼š{self.context.qimen_result.get('ç”¨ç¥å®«ä½', 'æœªçŸ¥')}
- æ ¼å±€ï¼š{pattern_str}
"""
            summary += qimen_summary

        # å¤§å…­å£¬ç»“æœ
        if self.context.liuren_result:
            # è¯¾ä½“æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œéœ€è¦æå–åç§°
            ke_ti = self.context.liuren_result.get('è¯¾ä½“', {})
            ke_ti_name = ke_ti.get('åç§°', 'æœªçŸ¥') if isinstance(ke_ti, dict) else str(ke_ti)
            # ä¸‰ä¼ æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œéœ€è¦æ ¼å¼åŒ–
            san_chuan = self.context.liuren_result.get('ä¸‰ä¼ ', [])
            san_chuan_str = 'â†’'.join([s.get('åœ°æ”¯', '') for s in san_chuan]) if san_chuan else 'æœªçŸ¥'
            liuren_summary = f"""
**å¤§å…­å£¬**ï¼š
- è¯¾ä½“ï¼š{ke_ti_name}
- ä¸‰ä¼ ï¼š{san_chuan_str}
- å‰å‡¶ï¼š{self.context.liuren_result.get('å‰å‡¶åˆ¤æ–­', 'æœªçŸ¥')}
"""
            summary += liuren_summary

        # å…­çˆ»ç»“æœ
        if self.context.liuyao_result:
            ben_gua = self.context.liuyao_result.get('æœ¬å¦', {})
            bian_gua = self.context.liuyao_result.get('å˜å¦')
            liuyao_summary = f"""
**å…­çˆ»**ï¼š
- æœ¬å¦ï¼š{ben_gua.get('å¦å', 'æœªçŸ¥') if isinstance(ben_gua, dict) else 'æœªçŸ¥'}
- å˜å¦ï¼š{bian_gua.get('å¦å', 'æœªçŸ¥') if isinstance(bian_gua, dict) and bian_gua else 'æ— '}
- ç”¨ç¥ï¼š{self.context.liuyao_result.get('ç”¨ç¥', 'æœªçŸ¥')}
"""
            summary += liuyao_summary

        # æ¢…èŠ±æ˜“æ•°ç»“æœ
        if self.context.meihua_result:
            meihua_summary = f"""
**æ¢…èŠ±æ˜“æ•°**ï¼š
- ä¸»å¦ï¼š{self.context.meihua_result.get('ä¸»å¦', {}).get('å¦å', 'æœªçŸ¥')}
- å˜å¦ï¼š{self.context.meihua_result.get('å˜å¦', {}).get('å¦å', 'æœªçŸ¥')}
- äº’å¦ï¼š{self.context.meihua_result.get('äº’å¦', {}).get('å¦å', 'æœªçŸ¥')}
"""
            summary += meihua_summary

        # æ—¶è¾°æ¨æ–­ä¿¡æ¯
        if self.context.time_certainty == "inferred":
            hour_name = self._hour_to_chinese(self.context.inferred_hour)
            summary += f"\n**æ—¶è¾°æ¨æ–­**ï¼šæ ¹æ®è¡¥å……ä¿¡æ¯æ¨æ–­ä¸º{hour_name}æ—¶ï¼ˆç½®ä¿¡åº¦70%ï¼‰\n"

        return summary if summary else "ï¼ˆæ— è¯¦ç»†åˆ†ææ•°æ®ï¼‰"

    def prepare_verification_summary(self) -> str:
        """
        å‡†å¤‡å›æº¯éªŒè¯æ‘˜è¦

        Returns:
            éªŒè¯æ‘˜è¦æ–‡æœ¬
        """
        if not self.context.verification_feedback:
            return "ï¼ˆç”¨æˆ·æœªæä¾›å›æº¯éªŒè¯åé¦ˆï¼‰"

        latest_feedback = self.context.verification_feedback[-1]
        parsed = latest_feedback.get("parsed_feedback", {})

        match_count = parsed.get("match_count", 0)
        total_count = parsed.get("total_count", 0)

        if total_count > 0:
            accuracy = (match_count / total_count) * 100
            return f"""
**å›æº¯éªŒè¯å‡†ç¡®ç‡**ï¼š{accuracy:.0f}% ({match_count}/{total_count}ä¸ªäº‹ä»¶ç¬¦åˆ)

éªŒè¯è¯¦æƒ…ï¼š
{json.dumps(parsed.get('matches', []), ensure_ascii=False, indent=2)[:300]}
"""
        else:
            return "ï¼ˆæ— å›æº¯éªŒè¯æ•°æ®ï¼‰"

    def calculate_overall_confidence(self) -> int:
        """
        è®¡ç®—ç»¼åˆç½®ä¿¡åº¦

        Returns:
            ç½®ä¿¡åº¦ç™¾åˆ†æ¯” (0-100)
        """
        base_confidence = 75  # åŸºç¡€ç½®ä¿¡åº¦

        # æ ¹æ®ç†è®ºæ•°é‡è°ƒæ•´
        theory_count = len(self.context.selected_theories)
        if theory_count >= 3:
            base_confidence += 10
        elif theory_count >= 2:
            base_confidence += 5

        # æ ¹æ®å›æº¯éªŒè¯è°ƒæ•´
        if self.context.verification_feedback:
            latest_feedback = self.context.verification_feedback[-1]
            parsed = latest_feedback.get("parsed_feedback", {})
            match_count = parsed.get("match_count", 0)
            total_count = parsed.get("total_count", 1)
            accuracy = match_count / total_count

            if accuracy >= 0.8:
                base_confidence += 10
            elif accuracy >= 0.5:
                base_confidence += 5
            else:
                base_confidence -= 10

        # æ ¹æ®æ—¶è¾°ç¡®å®šæ€§è°ƒæ•´
        if self.context.time_certainty == "certain":
            base_confidence += 5
        elif self.context.time_certainty == "inferred":
            base_confidence -= 5

        # é™åˆ¶åœ¨0-100èŒƒå›´å†…
        return max(0, min(100, base_confidence))

    def generate_simplified_report(self) -> str:
        """
        ç”Ÿæˆç®€åŒ–ç‰ˆæŠ¥å‘Šï¼ˆAIè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨ï¼‰

        Returns:
            ç®€åŒ–ç‰ˆæŠ¥å‘Šæ–‡æœ¬
        """
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M")

        return f"""# ğŸ”® èµ›åšç„æ•° - æ™ºèƒ½åˆ†ææŠ¥å‘Š

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

- **åˆ†ææ—¶é—´**ï¼š{current_time}
- **æ‰€é—®äº‹é¡¹**ï¼š{self.context.question_category} - {self.context.question_description}
- **ä½¿ç”¨ç†è®º**ï¼š{', '.join(self.context.selected_theories)}
- **ç»¼åˆç½®ä¿¡åº¦**ï¼š{self.calculate_overall_confidence()}%

---

## ğŸ¯ æ ¸å¿ƒç»“è®º

åŸºäº{', '.join(self.context.selected_theories)}çš„ç»¼åˆåˆ†æï¼Œæˆ‘ä»¬ä¸ºæ‚¨æä¾›äº†ä»¥ä¸‹å‚è€ƒå»ºè®®ã€‚

## ğŸ“Š åˆ†ææ‘˜è¦

{self.prepare_analysis_summary()}

## âª å›æº¯éªŒè¯

{self.prepare_verification_summary()}

---

ğŸ’¬ **å¦‚æœ‰ç–‘é—®ï¼Œæ¬¢è¿ç»§ç»­æé—®ï¼æˆ‘ä¼šä¸ºæ‚¨è¯¦ç»†è§£ç­”ã€‚**

**æ³¨æ„**ï¼šç”±äºç³»ç»Ÿç¹å¿™ï¼Œè¯¦ç»†æŠ¥å‘Šç”Ÿæˆå¤±è´¥ã€‚æ‚¨å¯ä»¥é’ˆå¯¹å…·ä½“é—®é¢˜ç»§ç»­æé—®ï¼Œæˆ‘ä¼šä¸ºæ‚¨è¯¦ç»†è§£ç­”ã€‚
"""

    def _hour_to_chinese(self, hour: Optional[int]) -> str:
        """
        å°†å°æ—¶è½¬æ¢ä¸ºä¸­æ–‡æ—¶è¾°å

        Args:
            hour: å°æ—¶æ•° (0-23)

        Returns:
            ä¸­æ–‡æ—¶è¾°å
        """
        if hour is None:
            return "æœªçŸ¥"
        return HOUR_CHINESE_NAMES.get(hour, "æœªçŸ¥")


class ConversationExporter:
    """
    å¯¹è¯å¯¼å‡ºå™¨

    è´Ÿè´£å°†å¯¹è¯å†…å®¹å¯¼å‡ºä¸ºå„ç§æ ¼å¼
    """

    def __init__(self, context: "ConversationContext"):
        """
        åˆå§‹åŒ–å¯¼å‡ºå™¨

        Args:
            context: å¯¹è¯ä¸Šä¸‹æ–‡
        """
        self.context = context

    def export_to_markdown(self) -> str:
        """
        å°†å¯¹è¯å¯¼å‡ºä¸ºMarkdownæ ¼å¼

        Returns:
            Markdownæ ¼å¼çš„å¯¹è¯å†…å®¹
        """
        md_content = f"""# èµ›åšç„æ•° - å¯¹è¯è®°å½•

**å¯¼å‡ºæ—¶é—´**ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**å¯¹è¯é˜¶æ®µ**ï¼š{self.context.stage.value}

---

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯

**é—®é¢˜ç±»åˆ«**ï¼š{self.context.question_category or 'æœªå¡«å†™'}
**é—®é¢˜æè¿°**ï¼š{self.context.question_description or 'æœªå¡«å†™'}

**å‡ºç”Ÿä¿¡æ¯**ï¼š
"""

        if self.context.birth_info:
            birth = self.context.birth_info
            md_content += f"""- å¹´ä»½ï¼š{birth.get('year')}å¹´
- æœˆä»½ï¼š{birth.get('month')}æœˆ
- æ—¥æœŸï¼š{birth.get('day')}æ—¥
- æ—¶è¾°ï¼š{birth.get('hour', 'æœªçŸ¥')}æ—¶
- å†æ³•ï¼š{'å†œå†' if birth.get('calendar_type') == 'lunar' else 'é˜³å†'}
- æ—¶è¾°ç¡®å®šæ€§ï¼š{self.context.time_certainty}
"""
        else:
            md_content += "- æœªå¡«å†™\n"

        md_content += f"""
**å…¶ä»–ä¿¡æ¯**ï¼š
- æ€§åˆ«ï¼š{self.context.gender or 'æœªå¡«å†™'}
- MBTIï¼š{self.context.mbti_type or 'æœªå¡«å†™'}

---

## ğŸ”® åˆ†ææ¦‚å†µ

**ä½¿ç”¨ç†è®º**ï¼š{', '.join(self.context.selected_theories) if self.context.selected_theories else 'æœªé€‰æ‹©'}

**åˆ†æçŠ¶æ€**ï¼š
- å°å…­å£¬ï¼š{'âœ“ å·²åˆ†æ' if self.context.xiaoliu_result else 'âœ— æœªåˆ†æ'}
- å…«å­—ï¼š{'âœ“ å·²åˆ†æ' if self.context.bazi_result else 'âœ— æœªåˆ†æ'}
- å¥‡é—¨éç”²ï¼š{'âœ“ å·²åˆ†æ' if self.context.qimen_result else 'âœ— æœªåˆ†æ'}
- å¤§å…­å£¬ï¼š{'âœ“ å·²åˆ†æ' if self.context.liuren_result else 'âœ— æœªåˆ†æ'}
- å…­çˆ»ï¼š{'âœ“ å·²åˆ†æ' if self.context.liuyao_result else 'âœ— æœªåˆ†æ'}
- æ¢…èŠ±æ˜“æ•°ï¼š{'âœ“ å·²åˆ†æ' if self.context.meihua_result else 'âœ— æœªåˆ†æ'}

---

## ğŸ’¬ å¯¹è¯å†å²

"""

        # æ·»åŠ å¯¹è¯å†å²
        for msg in self.context.conversation_history:
            role = "ğŸ‘¤ **ç”¨æˆ·**" if msg.get("role") == "user" else "ğŸ¤– **åŠ©æ‰‹**"
            content = msg.get("content", "")
            md_content += f"{role}ï¼š\n\n{content}\n\n---\n\n"

        if self.context.comprehensive_analysis:
            md_content += f"""## ğŸ“Š ç»¼åˆåˆ†ææŠ¥å‘Š

{self.context.comprehensive_analysis}

---
"""

        md_content += """
*æœ¬æŠ¥å‘Šç”±èµ›åšç„æ•°AIç³»ç»Ÿç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*
"""

        return md_content

    def to_save_dict(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆç”¨äºä¿å­˜çš„å­—å…¸

        Returns:
            åŒ…å«å®Œæ•´å¯¹è¯æ•°æ®çš„å­—å…¸
        """
        return {
            "timestamp": datetime.now().isoformat(),
            "session_id": id(self.context),
            "context": self.context.to_dict(),
            "full_conversation": self.context.conversation_history,
            "summary": self.get_summary(),
            "statistics": self.get_statistics()
        }

    def get_summary(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¯¹è¯æ‘˜è¦

        Returns:
            å¯¹è¯æ‘˜è¦å­—å…¸
        """
        return {
            "stage": self.context.stage.value,
            "question": {
                "category": self.context.question_category,
                "description": self.context.question_description[:100] + "..."
                if len(self.context.question_description) > 100
                else self.context.question_description
            },
            "user_info": {
                "birth_year": self.context.birth_info.get("year") if self.context.birth_info else None,
                "gender": self.context.gender,
                "mbti": self.context.mbti_type,
                "time_certainty": self.context.time_certainty
            },
            "analysis_status": {
                "theories_used": self.context.selected_theories,
                "bazi_analyzed": self.context.bazi_result is not None,
                "qimen_analyzed": self.context.qimen_result is not None,
                "liuren_analyzed": self.context.liuren_result is not None,
                "report_generated": bool(self.context.comprehensive_analysis)
            },
            "verification": {
                "retrospective_events_count": len(self.context.retrospective_events),
                "feedback_provided": len(self.context.verification_feedback) > 0,
                "confidence_adjusted": bool(self.context.theory_confidence_adjustment)
            }
        }

    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return {
            "total_messages": len(self.context.conversation_history),
            "user_messages": len([m for m in self.context.conversation_history if m.get("role") == "user"]),
            "assistant_messages": len([m for m in self.context.conversation_history if m.get("role") == "assistant"]),
            "theories_count": len(self.context.selected_theories),
            "has_xiaoliu": self.context.xiaoliu_result is not None,
            "has_bazi": self.context.bazi_result is not None,
            "has_report": bool(self.context.comprehensive_analysis)
        }
