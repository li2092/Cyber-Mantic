"""
ConversationService - çº¯AIå¯¹è¯æ¨¡å¼æœåŠ¡ï¼ˆV2é‡æ„ç‰ˆï¼‰

å®ç°æ¸è¿›å¼5é˜¶æ®µ8æ­¥éª¤æ™ºèƒ½äº¤äº’æµç¨‹ï¼š

V2æµç¨‹ï¼ˆ5é˜¶æ®µ8æ­¥éª¤ï¼‰ï¼š
- é˜¶æ®µ0: æ¬¢è¿ - å›ºå®šæ¬¢è¿æ¨¡æ¿
- é˜¶æ®µ1: ç ´å†° - å’¨è¯¢ç±»åˆ« + 3ä¸ªéšæœºæ•° â†’ å°å…­å£¬
- é˜¶æ®µ2: æ·±å…¥ - å…·ä½“æè¿° + æ±‰å­— â†’ æµ‹å­—æœ¯ï¼ˆV2æ–°å¢ï¼‰
- é˜¶æ®µ3: ä¿¡æ¯æ”¶é›† - ç”Ÿè¾°+æ€§åˆ«+MBTI â†’ å¤šç†è®º
- é˜¶æ®µ4: éªŒè¯ - å›æº¯éªŒè¯é—®é¢˜
- é˜¶æ®µ5: æŠ¥å‘Š - ç»¼åˆæŠ¥å‘Šï¼ˆAIå¤šè½®æ€è€ƒï¼‰
- é—®ç­”: æŒç»­é—®ç­”

æ¶æ„è¯´æ˜ï¼š
æœ¬æ¨¡å—é‡‡ç”¨å§”æ‰˜æ¨¡å¼ï¼Œå°†å…·ä½“é€»è¾‘å§”æ‰˜ç»™ä¸“é—¨çš„å¤„ç†å™¨ï¼š
- NLPParser: è‡ªç„¶è¯­è¨€è§£æ
- QAHandler: é—®ç­”å¤„ç†
- ReportGenerator: æŠ¥å‘Šç”Ÿæˆ
- FlowGuard: æµç¨‹ç›‘ç®¡ï¼ˆV2ï¼‰
- DynamicVerificationGenerator: å›æº¯é—®é¢˜ç”Ÿæˆï¼ˆV2ï¼‰
"""

import json
from typing import Dict, Any, Optional, Callable
from core.constants import DEFAULT_MAX_THEORIES, DEFAULT_MIN_THEORIES
from datetime import datetime

from api.manager import APIManager
from models import UserInput
from theories.bazi.theory import BaZiTheory
from theories.ziwei.theory import ZiWeiTheory
from theories.qimen.theory import QiMenTheory
from theories.daliuren.theory import DaLiuRenTheory
from theories.xiaoliu.theory import XiaoLiuRenTheory
from theories.liuyao.theory import LiuYaoTheory
from theories.meihua.theory import MeiHuaTheory
from theories.cezi.theory import CeZiTheory  # V2æ–°å¢ï¼šæµ‹å­—æœ¯
from core.theory_selector import TheorySelector
from utils.logger import get_logger

# ä»æ–°æ¨¡å—å¯¼å…¥ï¼ˆå§”æ‰˜ç›®æ ‡ï¼‰
from services.conversation.context import (
    ConversationStage,
    ConversationContext,
    MAX_CONVERSATION_HISTORY
)
from services.conversation.nlp_parser import NLPParser
from services.conversation.qa_handler import QAHandler, DEFAULT_QA_KEYWORDS
from services.conversation.report_generator import ReportGenerator, ConversationExporter
from utils.usage_stats_manager import get_usage_stats_manager

# V2: FlowGuardæµç¨‹ç›‘ç®¡
from core.flow_guard import get_flow_guard, InputStatus

# V2: æç¤ºè¯æ¨¡æ¿åŠ è½½å™¨
from prompts.loader import load_prompt, prompt_exists

# V2: åŠ¨æ€éªŒè¯é—®é¢˜ç”Ÿæˆ
from core.dynamic_verification import DynamicVerificationGenerator, VerificationResult as DynVerificationResult


# å¯¼å‡ºå…¬å…±æ¥å£ï¼ˆå‘åå…¼å®¹ï¼‰
__all__ = [
    'ConversationStage',
    'ConversationContext',
    'ConversationService',
    'MAX_CONVERSATION_HISTORY',
]


class ConversationService:
    """
    çº¯AIå¯¹è¯æ¨¡å¼æœåŠ¡ï¼ˆå§”æ‰˜é‡æ„ç‰ˆï¼‰

    é‡‡ç”¨å§”æ‰˜æ¨¡å¼ï¼Œå°†å…·ä½“å¤„ç†é€»è¾‘åˆ†å‘ç»™ä¸“é—¨çš„å¤„ç†å™¨ï¼Œ
    ä¿æŒå…¬å…±APIä¸å˜ä»¥ç¡®ä¿å‘åå…¼å®¹ã€‚
    """

    # é—®é¢˜ç±»åˆ«æ˜ å°„
    QUESTION_CATEGORIES = {
        "äº‹ä¸š": ["å·¥ä½œ", "èŒä¸š", "äº‹ä¸š", "è·³æ§½", "å‡èŒ", "åˆ›ä¸š"],
        "æ„Ÿæƒ…": ["æ„Ÿæƒ…", "æ‹çˆ±", "å©šå§»", "å§»ç¼˜", "æ¡ƒèŠ±", "åˆ†æ‰‹"],
        "è´¢è¿": ["è´¢è¿", "è´¢å¯Œ", "èµšé’±", "æŠ•èµ„", "ç†è´¢", "æ”¶å…¥"],
        "å¥åº·": ["å¥åº·", "èº«ä½“", "ç–¾ç—…", "å…»ç”Ÿ"],
        "å­¦ä¸š": ["å­¦ä¸š", "è€ƒè¯•", "å­¦ä¹ ", "å‡å­¦"],
        "å†³ç­–": ["å†³å®š", "é€‰æ‹©", "æ˜¯å¦"],
        "å…¶ä»–": []
    }

    # ç†è®ºé…ç½®æ˜ å°„ï¼ˆç”¨äºæ¶ˆé™¤é‡å¤ä»£ç ï¼‰
    THEORY_CONFIGS = {
        "å…«å­—": {
            "display_name": "å…«å­—",
            "progress_name": "å…«å­—",
            "progress_text": "æ­£åœ¨è®¡ç®—å…«å­—å‘½ç›˜...",
            "progress_value": 91,
            "theory_class": BaZiTheory,
            "context_attr": "bazi_result",
            "has_summary": True,
            "has_judgment": True,
        },
        "ç´«å¾®æ–—æ•°": {
            "display_name": "ç´«å¾®æ–—æ•°",
            "progress_name": "ç´«å¾®",
            "progress_text": "æ­£åœ¨æ’ç´«å¾®æ–—æ•°å‘½ç›˜...",
            "progress_value": 93,
            "theory_class": ZiWeiTheory,
            "context_attr": "ziwei_result",
            "has_summary": False,
            "default_summary": "å‘½ç›˜æ’å¸ƒå®Œæˆ",
            "has_judgment": False,
            "default_judgment": "å¹³",
        },
        "å¥‡é—¨éç”²": {
            "display_name": "å¥‡é—¨éç”²",
            "progress_name": "å¥‡é—¨",
            "progress_text": "æ­£åœ¨èµ·å¥‡é—¨å±€...",
            "progress_value": 94,
            "theory_class": QiMenTheory,
            "context_attr": "qimen_result",
            "has_summary": True,
            "has_judgment": True,
        },
        "å¤§å…­å£¬": {
            "display_name": "å¤§å…­å£¬",
            "progress_name": "å…­å£¬",
            "progress_text": "æ­£åœ¨èµ·å…­å£¬è¯¾...",
            "progress_value": 95,
            "theory_class": DaLiuRenTheory,
            "context_attr": "liuren_result",
            "has_summary": False,
            "default_summary": "å…­å£¬è¯¾èµ·æˆ",
            "has_judgment": False,
            "default_judgment": "å¹³",
        },
        "å…­çˆ»": {
            "display_name": "å…­çˆ»",
            "progress_name": "å…­çˆ»",
            "progress_text": "æ­£åœ¨èµ·å…­çˆ»å¦...",
            "progress_value": 96,
            "theory_class": LiuYaoTheory,
            "context_attr": "liuyao_result",
            "has_summary": True,
            "has_judgment": True,
        },
        "æ¢…èŠ±æ˜“æ•°": {
            "display_name": "æ¢…èŠ±æ˜“æ•°",
            "progress_name": "æ¢…èŠ±",
            "progress_text": "æ­£åœ¨èµ·æ¢…èŠ±å¦...",
            "progress_value": 97,
            "theory_class": MeiHuaTheory,
            "context_attr": "meihua_result",
            "has_summary": True,
            "has_judgment": True,
        },
    }

    def __init__(self, api_manager: APIManager, config: Optional[Dict[str, Any]] = None):
        self.api_manager = api_manager
        self.logger = get_logger(__name__)
        self.config = config or {}

        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
        self.context = ConversationContext()

        # åˆå§‹åŒ–ç†è®ºç»„ä»¶
        self.theory_selector = TheorySelector()
        self.xiaoliu_theory = XiaoLiuRenTheory()
        self.cezi_theory = CeZiTheory()  # V2æ–°å¢ï¼šæµ‹å­—æœ¯

        # åŠ è½½é…ç½®
        self._load_config()

        # åˆå§‹åŒ–å§”æ‰˜å¤„ç†å™¨
        self._init_handlers()

    def _load_config(self):
        """åŠ è½½é…ç½®"""
        conversation_config = self.config.get("conversation", {})
        qa_keywords_config = conversation_config.get("qa_keywords", {})
        self.qa_keywords = qa_keywords_config if qa_keywords_config else DEFAULT_QA_KEYWORDS
        self.max_history = conversation_config.get("max_history", MAX_CONVERSATION_HISTORY)

    def _init_handlers(self):
        """åˆå§‹åŒ–å§”æ‰˜å¤„ç†å™¨"""
        self.nlp_parser = NLPParser(self.api_manager)
        self.qa_handler = QAHandler(self.api_manager, self.context, self.qa_keywords)
        self.report_generator = ReportGenerator(self.api_manager, self.context)
        self.exporter = ConversationExporter(self.context)

        # V2: åˆå§‹åŒ–FlowGuardæµç¨‹ç›‘ç®¡ï¼ˆæ³¨å…¥APIç®¡ç†å™¨ï¼‰
        self.flow_guard = get_flow_guard(self.api_manager)

        # V2: åˆå§‹åŒ–åŠ¨æ€éªŒè¯é—®é¢˜ç”Ÿæˆå™¨
        self.verification_generator = DynamicVerificationGenerator(self.api_manager)

    # ==================== å…¬å…±API ====================

    async def start_conversation(
        self,
        progress_callback: Optional[Callable[[str, str, int], None]] = None,
        theory_callback: Optional[Callable[[str, str, dict], None]] = None
    ) -> str:
        """å¼€å§‹å¯¹è¯ä¼šè¯ - é˜¶æ®µ1ç ´å†°

        Args:
            progress_callback: è¿›åº¦å›è°ƒ (stage, message, progress)
            theory_callback: ç†è®ºåˆ†æå›è°ƒ (event_type, theory_name, data)
                event_type: 'started' | 'completed' | 'quick_result'
        """
        self.context = ConversationContext()
        self.context.stage = ConversationStage.STAGE1_ICEBREAK
        self._init_handlers()

        # V2: ä½¿ç”¨æ¨¡æ¿åŠ è½½æ¬¢è¿æ¶ˆæ¯
        try:
            welcome_message = load_prompt("conversation/welcome.md")
        except FileNotFoundError:
            self.logger.warning("æ¬¢è¿æ¶ˆæ¯æ¨¡æ¿ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¶ˆæ¯")
            welcome_message = "ğŸ‘‹ æ¬¢è¿ä½¿ç”¨èµ›åšç„æ•°ï¼è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³å’¨è¯¢ä»€ä¹ˆé—®é¢˜ï¼Œå¹¶æä¾›3ä¸ªéšæœºæ•°å­—ã€‚"
        self._add_message("assistant", welcome_message)
        return welcome_message

    async def process_user_input(
        self,
        user_message: str,
        progress_callback: Optional[Callable[[str, str, int], None]] = None,
        theory_callback: Optional[Callable[[str, str, dict], None]] = None
    ) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆè·¯ç”±åˆ°å¯¹åº”é˜¶æ®µï¼‰

        Args:
            user_message: ç”¨æˆ·è¾“å…¥
            progress_callback: è¿›åº¦å›è°ƒ (stage, message, progress)
            theory_callback: ç†è®ºåˆ†æå›è°ƒ (event_type, theory_name, data)
        """
        self._add_message("user", user_message)
        stage = self.context.stage

        # V2: åŒæ­¥FlowGuardé˜¶æ®µçŠ¶æ€
        self._sync_flow_guard_stage(stage)

        try:
            # V2: æ£€æµ‹ç”¨æˆ·æ˜¯å¦æƒ³ä¿®æ”¹å·²æ”¶é›†çš„ä¿¡æ¯
            if self.flow_guard.detect_modification_intent(user_message):
                mod_result = await self.flow_guard.process_modification(user_message, self.context)
                if mod_result:
                    self.logger.info(f"ç”¨æˆ·ä¿®æ”¹ä¿¡æ¯: {mod_result['modified']}")
                    response = mod_result["message"] + "\n\nè¯·ç»§ç»­å¯¹è¯ï¼Œæˆ–å‘Šè¯‰æˆ‘æ‚¨è¿˜éœ€è¦ä¿®æ”¹ä»€ä¹ˆã€‚"
                    self._add_message("assistant", response)
                    return response

            # V2: æ–°çš„é˜¶æ®µè·¯ç”±é€»è¾‘
            # INIT é˜¶æ®µä¹Ÿå½“ä½œç ´å†°é˜¶æ®µå¤„ç†ï¼ˆç”¨æˆ·å¯èƒ½åœ¨æ¬¢è¿æ¶ˆæ¯ä¹‹å‰å°±å‘é€äº†æ¶ˆæ¯ï¼‰
            if stage in (ConversationStage.INIT, ConversationStage.STAGE1_ICEBREAK):
                response = await self._handle_stage1(user_message, progress_callback, theory_callback)

            # V2æ–°å¢ï¼šé˜¶æ®µ2 æ·±å…¥ï¼ˆæµ‹å­—æœ¯ï¼‰
            elif stage == ConversationStage.STAGE2_DEEPEN:
                response = await self._handle_stage2_deepen(user_message, progress_callback, theory_callback)

            # V2: é˜¶æ®µ3 ä¿¡æ¯æ”¶é›†ï¼ˆåŸé˜¶æ®µ2+3åˆå¹¶ï¼‰
            elif stage == ConversationStage.STAGE3_COLLECT:
                response = await self._handle_stage3_collect(user_message, progress_callback, theory_callback)

            # V2: é˜¶æ®µ4 éªŒè¯
            elif stage == ConversationStage.STAGE4_VERIFY:
                response = await self._handle_stage4_verify(user_message, progress_callback, theory_callback)

            # V2: é˜¶æ®µ5 æŠ¥å‘Š
            elif stage == ConversationStage.STAGE5_REPORT:
                response = await self._handle_stage5_report(progress_callback, theory_callback)

            # é—®ç­”é˜¶æ®µ
            elif stage in (ConversationStage.QA, ConversationStage.COMPLETED):
                response = await self._handle_qa(user_message, progress_callback)

            # å‘åå…¼å®¹ï¼šæ—§é˜¶æ®µæšä¸¾ï¼ˆå¯èƒ½æ¥è‡ªæ—§çš„ä¿å­˜æ•°æ®ï¼‰
            elif hasattr(ConversationStage, 'STAGE2_BASIC_INFO') and stage == ConversationStage.STAGE2_BASIC_INFO:
                response = await self._handle_stage3_collect(user_message, progress_callback, theory_callback)
            elif hasattr(ConversationStage, 'STAGE3_SUPPLEMENT') and stage == ConversationStage.STAGE3_SUPPLEMENT:
                response = await self._handle_stage3_collect(user_message, progress_callback, theory_callback)
            elif hasattr(ConversationStage, 'STAGE4_VERIFICATION') and stage == ConversationStage.STAGE4_VERIFICATION:
                response = await self._handle_stage4_verify(user_message, progress_callback, theory_callback)
            elif hasattr(ConversationStage, 'STAGE5_FINAL_REPORT') and stage == ConversationStage.STAGE5_FINAL_REPORT:
                response = await self._handle_stage5_report(progress_callback, theory_callback)

            else:
                response = "ç³»ç»Ÿé”™è¯¯ï¼šæœªçŸ¥çš„å¯¹è¯é˜¶æ®µ"
                self.logger.error(f"æœªçŸ¥å¯¹è¯é˜¶æ®µ: {stage}")

            self._add_message("assistant", response)
            return response

        except Exception as e:
            self.logger.error(f"å¤„ç†ç”¨æˆ·è¾“å…¥å¤±è´¥: {e}")
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¾“å…¥æ—¶é‡åˆ°é—®é¢˜ï¼š{str(e)}\nè¯·é‡è¯•æˆ–æ¢ä¸ªæ–¹å¼è¡¨è¾¾ã€‚"
            self._add_message("assistant", error_msg)
            return error_msg

    def _sync_flow_guard_stage(self, stage: ConversationStage):
        """åŒæ­¥FlowGuardé˜¶æ®µçŠ¶æ€ï¼ˆV2æ›´æ–°ï¼‰"""
        stage_mapping = {
            # V2æ–°é˜¶æ®µæ˜ å°„
            ConversationStage.INIT: "STAGE1_ICEBREAK",
            ConversationStage.STAGE1_ICEBREAK: "STAGE1_ICEBREAK",
            ConversationStage.STAGE2_DEEPEN: "STAGE2_DEEPEN",      # V2æ–°å¢
            ConversationStage.STAGE3_COLLECT: "STAGE3_COLLECT",    # V2é‡å‘½å
            ConversationStage.STAGE4_VERIFY: "STAGE4_VERIFY",      # V2é‡å‘½å
            ConversationStage.STAGE5_REPORT: "STAGE5_REPORT",      # V2é‡å‘½å
        }
        flow_guard_stage = stage_mapping.get(stage)
        if flow_guard_stage:
            self.flow_guard.set_stage(flow_guard_stage)

    # ==================== é˜¶æ®µå¤„ç† ====================

    async def _handle_stage1(self, user_message: str, progress_callback, theory_callback=None) -> str:
        """
        é˜¶æ®µ1ï¼šç ´å†° - è§£æé—®é¢˜ç±»åˆ«å’Œéšæœºæ•°å­—ï¼Œå°å…­å£¬èµ·å¦

        V2æ›´æ–°ï¼š
        - è®°å½•èµ·å¦æ—¶é—´ï¼ˆç”¨äºåç»­å…­çˆ»ã€æ¢…èŠ±ï¼‰
        - è½¬åˆ°é˜¶æ®µ2æ·±å…¥ï¼ˆæµ‹å­—æœ¯ï¼‰è€Œä¸æ˜¯ç›´æ¥æ”¶é›†å‡ºç”Ÿä¿¡æ¯
        """
        # å¼€å§‹ä¼šè¯è¿½è¸ª
        try:
            stats_manager = get_usage_stats_manager()
            session_id = stats_manager.start_session(
                module='wendao',
                stage='stage1_icebreak'
            )
            self.context.session_id = session_id
        except Exception as e:
            self.logger.warning(f"å¼€å§‹ä¼šè¯è¿½è¸ªå¤±è´¥: {e}")

        if progress_callback:
            progress_callback("é˜¶æ®µ1", "æ­£åœ¨è§£ææ‚¨çš„é—®é¢˜å’Œéšæœºæ•°å­—...", 10)

        # V2: è®°å½•èµ·å¦æ—¶é—´ï¼ˆå…³é”®ï¼ç”¨äºå…­çˆ»ã€æ¢…èŠ±æ—¶é—´èµ·å¦ï¼‰
        self.context.qigua_time = datetime.now()

        # V2: FlowGuardè¾“å…¥éªŒè¯ï¼ˆAIä¼˜å…ˆï¼Œä»£ç åå¤‡ï¼‰
        validation_result = await self.flow_guard.validate_input_with_ai(user_message, "STAGE1_ICEBREAK")

        if validation_result.status == InputStatus.VALID:
            # FlowGuardæˆåŠŸæå–ï¼Œä½¿ç”¨æå–çš„æ•°æ®
            self.context.question_category = validation_result.extracted_data.get("question_category")
            self.context.random_numbers = validation_result.extracted_data.get("random_numbers", [])
            self.logger.debug(f"FlowGuardéªŒè¯æˆåŠŸ: {validation_result.extracted_data}")
        else:
            # FlowGuardéªŒè¯å¤±è´¥ï¼Œå›é€€åˆ°NLPè§£æ
            self.logger.debug(f"FlowGuardéªŒè¯: {validation_result.status}, ä½¿ç”¨NLPè§£æ")

            # NLPè§£æä½œä¸ºå¤‡ç”¨
            parsed_info = await self.nlp_parser.parse_icebreak_input(user_message)
            if not parsed_info or "error" in parsed_info:
                return self._retry_msg("stage1")

            # ä½¿ç”¨NLPè§£æçš„æ•°æ®
            self.context.question_category = parsed_info.get("category")
            self.context.random_numbers = parsed_info.get("numbers", [])

        if progress_callback:
            progress_callback("å°å…­å£¬", "æ­£åœ¨ç”¨å°å…­å£¬èµ·å¦...", 30)

        # V2: é€šçŸ¥ç†è®ºå¼€å§‹
        if theory_callback:
            theory_callback('started', 'å°å…­å£¬', None)

        xiaoliu_result = self._calculate_xiaoliu()
        self.context.xiaoliu_result = xiaoliu_result

        # V2: é€šçŸ¥ç†è®ºå®Œæˆ
        if theory_callback:
            theory_callback('completed', 'å°å…­å£¬', {
                'summary': xiaoliu_result.get('åˆ¤æ–­', 'åˆæ­¥åˆ¤æ–­å®Œæˆ'),
                'judgment': self._get_xiaoliu_judgment(xiaoliu_result)
            })

        if progress_callback:
            progress_callback("å°å…­å£¬", "æ­£åœ¨ç”Ÿæˆåˆæ­¥åˆ¤æ–­...", 50)

        interpretation = await self._interpret_xiaoliu(xiaoliu_result)

        # V2: è½¬åˆ°é˜¶æ®µ2æ·±å…¥ï¼ˆæµ‹å­—æœ¯ï¼‰ï¼Œè€Œä¸æ˜¯ç›´æ¥æ”¶é›†å‡ºç”Ÿä¿¡æ¯
        self.context.stage = ConversationStage.STAGE2_DEEPEN

        if progress_callback:
            progress_callback("é˜¶æ®µ1", "ç ´å†°é˜¶æ®µå®Œæˆ", 100)

        # V2: ç”Ÿæˆé˜¶æ®µ1å®Œæˆæ¶ˆæ¯ï¼ˆè¿½é—®å…·ä½“æè¿°+æ±‰å­—ï¼‰
        try:
            return load_prompt("conversation/stage1_complete.md", {
                "category": self.context.question_category,
                "numbers": ', '.join(map(str, self.context.random_numbers)),
                "interpretation": interpretation
            })
        except FileNotFoundError:
            # å…œåº•ï¼šè¿”å›ç®€å•æ¶ˆæ¯
            return f"""âœ… å·²æ”¶é›†ï¼š{self.context.question_category}ï¼Œæ•°å­—ï¼š{', '.join(map(str, self.context.random_numbers))}

{interpretation}

---

è¯·å‘Šè¯‰æˆ‘ï¼š
1. å…·ä½“æ˜¯ä»€ä¹ˆäº‹æƒ…ï¼Ÿï¼ˆç®€å•æè¿°å³å¯ï¼‰
2. æƒ³ç€è¿™ä»¶äº‹ï¼Œè„‘æµ·ä¸­æµ®ç°çš„ç¬¬ä¸€ä¸ªæ±‰å­—æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆå¯ä»¥æ˜¯å¿ƒæ€ã€æœªæ¥çš„æ†§æ†¬ã€å½“ä¸‹æƒ³åšçš„åŠ¨ä½œç­‰ï¼‰"""

    async def _handle_stage2_deepen(self, user_message: str, progress_callback, theory_callback=None) -> str:
        """
        V2æ–°å¢ï¼šé˜¶æ®µ2 æ·±å…¥ - è§£æå…·ä½“æè¿°å’Œæ±‰å­—ï¼Œæµ‹å­—æœ¯åˆ†æ

        è¾“å…¥ï¼šå…·ä½“äº‹æƒ…æè¿° + æ±‰å­—
        è¾“å‡ºï¼šå°å…­å£¬+æµ‹å­—æœ¯ç»¼åˆåˆ†æ + è¿½é—®ç”Ÿè¾°ä¿¡æ¯
        """
        # æ›´æ–°ä¼šè¯é˜¶æ®µ
        self._update_session_stage('stage2_deepen')

        if progress_callback:
            progress_callback("é˜¶æ®µ2", "æ­£åœ¨è§£ææ‚¨çš„æè¿°å’Œæ±‰å­—...", 20)

        # V2: FlowGuardè¾“å…¥éªŒè¯
        validation_result = await self.flow_guard.validate_input_with_ai(user_message, "STAGE2_DEEPEN")
        if validation_result.status == InputStatus.VALID:
            self.context.question_description = validation_result.extracted_data.get("question_description", "")
            self.context.character = validation_result.extracted_data.get("character")
        else:
            self.logger.debug(f"FlowGuardéªŒè¯: {validation_result.status}")

        # å¦‚æœFlowGuardæ²¡æœ‰æå–åˆ°ï¼Œå°è¯•ä»æ¶ˆæ¯ä¸­ç®€å•æå–
        if not self.context.question_description:
            # å‡è®¾æ•´æ¡æ¶ˆæ¯æ˜¯æè¿°
            self.context.question_description = user_message[:200]

        if not self.context.character:
            # å°è¯•æå–ç¬¬ä¸€ä¸ªæ±‰å­—
            self.context.character = self.flow_guard.validate_character(user_message)

        # å¦‚æœä»ç„¶æ²¡æœ‰æ±‰å­—ï¼Œæç¤ºç”¨æˆ·
        if not self.context.character:
            return """ğŸ˜… æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°æ‚¨æƒ³æµ‹çš„æ±‰å­—ã€‚

è¯·å‘Šè¯‰æˆ‘ï¼šæƒ³ç€è¿™ä»¶äº‹ï¼Œè„‘æµ·ä¸­æµ®ç°çš„ç¬¬ä¸€ä¸ªæ±‰å­—æ˜¯ä»€ä¹ˆï¼Ÿ

ä¾‹å¦‚ï¼š
- "å˜" - æƒ³è¦æ”¹å˜
- "å¿ƒ" - å…³äºå†…å¿ƒ
- "è¿›" - æƒ³è¦å‰è¿›

æ‚¨ä¹Ÿå¯ä»¥è¿™æ ·è¯´ï¼š"æˆ‘æƒ³æµ‹'å˜'å­—" æˆ– "æƒ³åˆ°çš„å­—æ˜¯å˜"""

        if progress_callback:
            progress_callback("æµ‹å­—æœ¯", "æ­£åœ¨è¿›è¡Œæµ‹å­—åˆ†æ...", 40)

        # V2: é€šçŸ¥ç†è®ºå¼€å§‹
        if theory_callback:
            theory_callback('started', 'æµ‹å­—æœ¯', None)

        # V2: æ‰§è¡Œæµ‹å­—æœ¯è®¡ç®—
        try:
            cezi_user_input = UserInput(
                question_type=self.context.question_category,
                question_description=self.context.question_description,
                current_time=self.context.qigua_time or datetime.now()
            )
            # æµ‹å­—æœ¯éœ€è¦ character å­—æ®µ
            cezi_user_input.character = self.context.character

            cezi_result = self.cezi_theory.calculate(cezi_user_input)
            self.context.cezi_result = cezi_result

            # V2: é€šçŸ¥ç†è®ºå®Œæˆ
            if theory_callback:
                theory_callback('completed', 'æµ‹å­—æœ¯', {
                    'summary': cezi_result.get('ç®€æ', f"æµ‹'{self.context.character}'å­—å®Œæˆ"),
                    'judgment': cezi_result.get('judgment', 'å¹³')
                })
        except Exception as e:
            self.logger.error(f"æµ‹å­—æœ¯è®¡ç®—å¤±è´¥: {e}")
            self.context.cezi_result = {"error": str(e), "character": self.context.character}
            if theory_callback:
                theory_callback('completed', 'æµ‹å­—æœ¯', {
                    'summary': f"æµ‹'{self.context.character}'å­—",
                    'judgment': 'å¹³'
                })

        if progress_callback:
            progress_callback("ç»¼åˆåˆ†æ", "æ­£åœ¨ç”Ÿæˆç»¼åˆåˆ†æ...", 60)

        # V2: ç”Ÿæˆå°å…­å£¬+æµ‹å­—ç»¼åˆåˆ†æï¼ˆAIç”Ÿæˆï¼‰
        combined_analysis = await self._generate_combined_analysis()

        # V2: è½¬åˆ°é˜¶æ®µ3ä¿¡æ¯æ”¶é›†
        self.context.stage = ConversationStage.STAGE3_COLLECT

        if progress_callback:
            progress_callback("é˜¶æ®µ2", "æ·±å…¥é˜¶æ®µå®Œæˆ", 100)

        # V2: ç”Ÿæˆé˜¶æ®µ2å®Œæˆæ¶ˆæ¯ï¼ˆè¿½é—®ç”Ÿè¾°ä¿¡æ¯ï¼‰
        try:
            return load_prompt("conversation/stage2_complete.md", {
                "character": self.context.character,
                "description": self.context.question_description,
                "combined_analysis": combined_analysis
            })
        except FileNotFoundError:
            # å…œåº•ï¼šè¿”å›ç®€å•æ¶ˆæ¯
            return f"""âœ… å·²æ”¶é›†ï¼šæµ‹"{self.context.character}"å­—

{combined_analysis}

---

è¯·æä¾›æ‚¨çš„å‡ºç”Ÿä¿¡æ¯ï¼š
1. å‡ºç”Ÿæ—¥æœŸï¼ˆå¯ä»¥è¯´å¤§æ¦‚æ—¶é—´æ®µæˆ–ä¸è®°å¾—ï¼‰
2. æ€§åˆ«
3. MBTIç±»å‹ï¼ˆå¯é€‰ï¼Œä¸çŸ¥é“å¯è·³è¿‡ï¼‰"""

    async def _generate_combined_analysis(self) -> str:
        """V2æ–°å¢ï¼šç”Ÿæˆå°å…­å£¬+æµ‹å­—ç»¼åˆåˆ†æ"""
        prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šå°å…­å£¬å’Œæµ‹å­—æœ¯çš„å åœå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¸¤ç§ç†è®ºçš„ç»“æœï¼Œç»™å‡ºç»¼åˆåˆ†æã€‚

é—®é¢˜ç±»åˆ«ï¼š{self.context.question_category}
å…·ä½“äº‹æƒ…ï¼š{self.context.question_description}

ã€å°å…­å£¬ç»“æœã€‘
{json.dumps(self.context.xiaoliu_result, ensure_ascii=False, indent=2)}

ã€æµ‹å­—ç»“æœã€‘
æµ‹å­—ï¼š{self.context.character}
{json.dumps(self.context.cezi_result, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆç»¼åˆåˆ†æï¼ˆ100-150å­—ï¼‰ï¼Œèåˆä¸¤ç§ç†è®ºçš„åˆ¤æ–­ï¼Œç»™å‡ºåˆæ­¥å»ºè®®ã€‚è¯­æ°”æ¸©å’Œä¸“ä¸šã€‚
"""
        try:
            return (await self.api_manager.call_api(
                task_type="å¿«é€Ÿäº¤äº’é—®ç­”",
                prompt=prompt,
                enable_dual_verification=False
            )).strip()
        except Exception as e:
            self.logger.error(f"ç»¼åˆåˆ†æç”Ÿæˆå¤±è´¥: {e}")
            return f"ğŸ“ å°å…­å£¬è½å®«ï¼š{self.context.xiaoliu_result.get('æ—¶è½å®«', 'æœªçŸ¥')}ï¼Œæµ‹å­—ï¼š{self.context.character}\n\nï¼ˆç³»ç»Ÿç¹å¿™ï¼Œå°†åœ¨åç»­åˆ†æä¸­è¡¥å……è¯¦ç»†è§£è¯»ï¼‰"

    # ==================== å‘åå…¼å®¹ï¼šæ—§é˜¶æ®µå¤„ç†å™¨ ====================

    async def _handle_stage2(self, user_message: str, progress_callback, theory_callback=None) -> str:
        """[å·²åºŸå¼ƒ] é˜¶æ®µ2ï¼šåŸºç¡€ä¿¡æ¯æ”¶é›† - å·²åˆå¹¶åˆ° _handle_stage3_collect"""
        return await self._handle_stage3_collect(user_message, progress_callback, theory_callback)

    async def _handle_stage3(self, user_message: str, progress_callback, theory_callback=None) -> str:
        """[å·²åºŸå¼ƒ] é˜¶æ®µ3ï¼šæ·±åº¦è¡¥å…… - å·²åˆå¹¶åˆ° _handle_stage3_collect"""
        return await self._handle_stage3_collect(user_message, progress_callback, theory_callback)

    async def _handle_stage4(self, user_message: str, progress_callback, theory_callback=None) -> str:
        """[å·²åºŸå¼ƒ] é˜¶æ®µ4ï¼šç»“æœéªŒè¯ - å·²é‡å‘½åä¸º _handle_stage4_verify"""
        return await self._handle_stage4_verify(user_message, progress_callback, theory_callback)

    async def _handle_stage5(self, progress_callback, theory_callback=None) -> str:
        """[å·²åºŸå¼ƒ] é˜¶æ®µ5ï¼šæœ€ç»ˆæŠ¥å‘Š - å·²é‡å‘½åä¸º _handle_stage5_report"""
        return await self._handle_stage5_report(progress_callback, theory_callback)

    # ==================== V2ï¼šæ–°é˜¶æ®µå¤„ç†å™¨ ====================

    async def _handle_stage3_collect(self, user_message: str, progress_callback, theory_callback=None) -> str:
        """
        V2ï¼šé˜¶æ®µ3 ä¿¡æ¯æ”¶é›† - æ”¶é›†ç”Ÿè¾°+æ€§åˆ«+MBTIï¼Œè¿è¡Œå¤šç†è®ºåˆ†æ

        V2æ›´æ–°ï¼š
        - ä½¿ç”¨ STAGE3_COLLECT FlowGuardéªŒè¯
        - ç”Ÿæˆå…­çˆ»è‡ªåŠ¨èµ·å¦æ•°å­—
        - ç›´æ¥è½¬åˆ° STAGE4_VERIFYï¼ˆä¸å†æœ‰è¡¥å……é˜¶æ®µï¼‰
        """
        # æ›´æ–°ä¼šè¯é˜¶æ®µ
        self._update_session_stage('stage3_collect')

        if progress_callback:
            progress_callback("é˜¶æ®µ3", "æ­£åœ¨è§£ææ‚¨çš„å‡ºç”Ÿä¿¡æ¯...", 60)

        # V2: FlowGuardè¾“å…¥éªŒè¯
        validation_result = await self.flow_guard.validate_input_with_ai(user_message, "STAGE3_COLLECT")
        if validation_result.status == InputStatus.VALID:
            self.logger.info(f"FlowGuardéªŒè¯é€šè¿‡ï¼Œæå–æ•°æ®: {validation_result.extracted_data}")
            # æå–é¢œè‰²/æ–¹ä½ï¼ˆç”¨äºæ¢…èŠ±æ˜“æ•°ï¼‰
            if validation_result.extracted_data.get("favorite_color"):
                self.context.favorite_color = validation_result.extracted_data["favorite_color"]
            if validation_result.extracted_data.get("current_direction"):
                self.context.current_direction = validation_result.extracted_data["current_direction"]

        birth_info = await self.nlp_parser.parse_birth_info(user_message)
        if not birth_info or "error" in birth_info:
            return self._retry_msg("stage3")

        self.context.birth_info = birth_info
        self.context.gender = birth_info.get("gender")
        self.context.mbti_type = birth_info.get("mbti")
        self.context.time_certainty = birth_info.get("time_certainty", "unknown")

        # V2: ç”Ÿæˆå…­çˆ»è‡ªåŠ¨èµ·å¦æ•°å­—
        self.context.generate_liuyao_numbers()
        self.logger.info(f"å…­çˆ»è‡ªåŠ¨èµ·å¦æ•°å­—: {self.context.liuyao_numbers}")

        if progress_callback:
            progress_callback("å¤šç†è®ºåˆ†æ", "æ­£åœ¨è®¡ç®—å¤šç†è®ºç»“æœ...", 75)

        # è¿è¡Œå¤šç†è®ºåˆ†æ
        await self._run_deep_analysis(progress_callback, theory_callback)

        # V2: ç”Ÿæˆå›æº¯éªŒè¯é—®é¢˜
        if progress_callback:
            progress_callback("éªŒè¯é—®é¢˜", "æ­£åœ¨ç”Ÿæˆå›æº¯éªŒè¯é—®é¢˜...", 85)

        verification_questions = await self._generate_verification_questions()
        self.context.verification_questions = verification_questions

        # V2: ç›´æ¥è½¬åˆ°é˜¶æ®µ4éªŒè¯
        self.context.stage = ConversationStage.STAGE4_VERIFY

        # æ„å»ºå“åº”
        birth_str = f"{birth_info.get('year')}å¹´{birth_info.get('month')}æœˆ{birth_info.get('day')}æ—¥"
        if birth_info.get('hour') is not None:
            birth_str += f" {birth_info.get('hour')}æ—¶"

        time_status = {"certain": "âœ… ç¡®å®š", "uncertain": "âš ï¸ ä¸ç¡®å®š", "unknown": "â“ æœªçŸ¥"}.get(self.context.time_certainty, "æœªçŸ¥")

        # V2: æ ¼å¼åŒ–éªŒè¯é—®é¢˜
        questions_md = self._format_verification_questions(verification_questions)

        # V2: ä½¿ç”¨æ¨¡æ¿åŠ è½½é˜¶æ®µ3å®Œæˆæ¶ˆæ¯
        try:
            response = load_prompt("conversation/stage3_collect_complete.md", {
                "birth_str": birth_str,
                "time_status": time_status,
                "gender": self.context.gender or 'æœªæä¾›',
                "mbti": self.context.mbti_type or 'æœªæä¾›',
                "questions": questions_md
            })
        except FileNotFoundError:
            response = f"""âœ… å‡ºç”Ÿä¿¡æ¯ï¼š{birth_str}ï¼Œæ—¶è¾°ï¼š{time_status}
æ€§åˆ«ï¼š{self.context.gender or 'æœªæä¾›'}
MBTIï¼š{self.context.mbti_type or 'æœªæä¾›'}

---

å¤šç†è®ºåˆ†æå·²å®Œæˆã€‚

{questions_md}"""

        return response

    async def _handle_stage4_verify(self, user_message: str, progress_callback, theory_callback=None) -> str:
        """
        V2ï¼šé˜¶æ®µ4 éªŒè¯ - å¤„ç†å›æº¯éªŒè¯é—®é¢˜å›ç­”

        V2æ›´æ–°ï¼š
        - ä½¿ç”¨ STAGE4_VERIFY FlowGuardéªŒè¯
        - ç›´æ¥è½¬åˆ° STAGE5_REPORT
        """
        # æ›´æ–°ä¼šè¯é˜¶æ®µ
        self._update_session_stage('stage4_verify')

        if progress_callback:
            progress_callback("é˜¶æ®µ4", "æ­£åœ¨åˆ†æéªŒè¯åé¦ˆ...", 85)

        feedback = await self.nlp_parser.parse_verification_feedback(
            user_message,
            self.context.retrospective_events
        )
        if feedback:
            self.context.verification_feedback.append({
                "raw_message": user_message,
                "parsed_feedback": feedback
            })
            self._adjust_confidence(feedback)

        # V2: è½¬åˆ°é˜¶æ®µ5æŠ¥å‘Š
        self.context.stage = ConversationStage.STAGE5_REPORT

        return await self._handle_stage5_report(progress_callback, theory_callback)

    async def _handle_stage5_report(self, progress_callback, theory_callback=None) -> str:
        """
        V2ï¼šé˜¶æ®µ5 æŠ¥å‘Š - ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š

        V2æ›´æ–°ï¼š
        - æ”¯æŒå¤šè½®AIæ€è€ƒç”Ÿæˆä¸ªæ€§åŒ–æŠ¥å‘Š
        """
        if progress_callback:
            progress_callback("æŠ¥å‘Šç”Ÿæˆ", "æ­£åœ¨ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...", 95)

        self.report_generator.context = self.context
        report = await self.report_generator.generate_final_report()
        self.context.stage = ConversationStage.QA

        if progress_callback:
            progress_callback("å®Œæˆ", "æŠ¥å‘Šç”Ÿæˆå®Œæˆ", 100)

        # è®°å½•ä½¿ç”¨ç»Ÿè®¡
        try:
            stats_manager = get_usage_stats_manager()
            # ä»å­—å…¸ä¸­æå–ç†è®ºåç§°
            primary_theory = None
            if self.context.selected_theories:
                first_theory = self.context.selected_theories[0]
                if isinstance(first_theory, dict):
                    primary_theory = first_theory.get('theory', str(first_theory))
                else:
                    primary_theory = str(first_theory)
            stats_manager.record_usage(
                module='wendao',
                theory=primary_theory,
                question_type=self.context.question_category
            )
            # æ ‡è®°ä¼šè¯å®Œæˆ
            if self.context.session_id:
                stats_manager.complete_session(
                    session_id=self.context.session_id,
                    theory=primary_theory,
                    question_type=self.context.question_category
                )
        except Exception as e:
            self.logger.warning(f"è®°å½•ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")

        return report

    async def _handle_qa(self, user_message: str, progress_callback) -> str:
        """å¤„ç†é—®ç­”é˜¶æ®µ"""
        self.qa_handler.context = self.context
        return await self.qa_handler.handle(user_message, progress_callback)

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def _add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        self.context.conversation_history.append({"role": role, "content": content})
        if len(self.context.conversation_history) > self.max_history:
            self.context.conversation_history = self.context.conversation_history[-self.max_history:]

    def _update_session_stage(self, stage: str):
        """æ›´æ–°ä¼šè¯é˜¶æ®µï¼ˆç”¨äºè¿½è¸ªæµå¤±ç‚¹ï¼‰"""
        if self.context.session_id:
            try:
                stats_manager = get_usage_stats_manager()
                stats_manager.update_session_stage(self.context.session_id, stage)
            except Exception as e:
                self.logger.warning(f"æ›´æ–°ä¼šè¯é˜¶æ®µå¤±è´¥: {e}")

    async def _generate_verification_questions(self):
        """V2: ç”Ÿæˆå›æº¯éªŒè¯é—®é¢˜"""
        try:
            # å‡†å¤‡ç”¨æˆ·ä¿¡æ¯
            user_info = {
                "question_type": self.context.question_category,
                "age": self._calculate_age(),
                "gender": self.context.gender or "æœªçŸ¥"
            }

            # å‡†å¤‡åˆ†æç»“æœï¼ˆå·²æœ‰çš„ç†è®ºåˆ†æï¼‰
            analysis_results = {}
            if self.context.xiaoliu_result:
                analysis_results["å°å…­å£¬"] = self.context.xiaoliu_result

            # ç”Ÿæˆ3ä¸ªéªŒè¯é—®é¢˜
            questions = await self.verification_generator.generate_questions(
                user_info=user_info,
                analysis_results=analysis_results,
                question_count=3
            )

            self.logger.info(f"ç”Ÿæˆäº† {len(questions)} ä¸ªå›æº¯éªŒè¯é—®é¢˜")
            return questions

        except Exception as e:
            self.logger.error(f"ç”ŸæˆéªŒè¯é—®é¢˜å¤±è´¥: {e}")
            return []

    def _format_verification_questions(self, questions) -> str:
        """V2: æ ¼å¼åŒ–éªŒè¯é—®é¢˜ä¸ºMarkdown"""
        if not questions:
            # æ²¡æœ‰ç”Ÿæˆé—®é¢˜æ—¶ä½¿ç”¨é»˜è®¤é—®é¢˜
            return f"""## âª å›æº¯éªŒè¯

è¯·ç®€å•å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå¸®åŠ©æˆ‘ä»¬éªŒè¯åˆ†æå‡†ç¡®åº¦ï¼š

1. è¿‡å»3å¹´ä¸­ï¼Œåœ¨**{self.context.question_category}**é¢†åŸŸæ˜¯å¦æœ‰é‡å¤§å˜åŒ–ï¼Ÿ
2. æ‚¨æœ€è¿‘ä¸€æ¬¡é‡è¦å†³ç­–æ˜¯åœ¨ä»€ä¹ˆæ—¶å€™ï¼Ÿ
3. è¿‡å»ä¸€å¹´çš„å‘å±•æ˜¯å¦ç¬¦åˆæ‚¨çš„é¢„æœŸï¼Ÿ

è¯·ç®€å•æè¿°ï¼š"""

        # æ ¼å¼åŒ–é—®é¢˜åˆ—è¡¨
        lines = ["## âª å›æº¯éªŒè¯\n", "è¯·ç®€å•å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå¸®åŠ©æˆ‘ä»¬éªŒè¯åˆ†æå‡†ç¡®åº¦ï¼š\n"]

        for i, q in enumerate(questions, 1):
            lines.append(f"{i}. {q.question}")

        lines.append("\nè¯·ç®€å•å›ç­”ï¼ˆå¯ä»¥ä¸€èµ·å›ç­”ï¼Œä¹Ÿå¯ä»¥é€ä¸ªå›ç­”ï¼‰ï¼š")

        return "\n".join(lines)

    def _calculate_age(self) -> int:
        """è®¡ç®—ç”¨æˆ·å¹´é¾„"""
        if self.context.birth_info and self.context.birth_info.get("year"):
            birth_year = self.context.birth_info["year"]
            current_year = datetime.now().year
            return current_year - birth_year
        return 0

    def _calculate_xiaoliu(self) -> Dict[str, Any]:
        """è®¡ç®—å°å…­å£¬"""
        user_input = UserInput(
            question_type=self.context.question_category,
            question_description=self.context.question_description,
            numbers=self.context.random_numbers,
            current_time=datetime.now()
        )
        return self.xiaoliu_theory.calculate(user_input)

    async def _interpret_xiaoliu(self, result: Dict[str, Any]) -> str:
        """ç”¨AIè§£è¯»å°å…­å£¬ç»“æœ"""
        prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šå°å…­å£¬çš„å åœå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹å°å…­å£¬å¦è±¡ï¼Œç»™å‡ºç®€æ´çš„åˆæ­¥åˆ¤æ–­ã€‚

é—®é¢˜ç±»åˆ«ï¼š{self.context.question_category}
é—®é¢˜æè¿°ï¼š{self.context.question_description}

å°å…­å£¬ç»“æœï¼š
```json
{json.dumps(result, ensure_ascii=False, indent=2)}
```

è¯·ç”Ÿæˆç®€æ´çš„è§£è¯»ï¼ˆ80-100å­—ï¼‰ï¼ŒåŒ…æ‹¬è½å®«å‰å‡¶å’Œåˆæ­¥å»ºè®®ã€‚
"""
        try:
            return (await self.api_manager.call_api(task_type="å¿«é€Ÿäº¤äº’é—®ç­”", prompt=prompt, enable_dual_verification=False)).strip()
        except Exception as e:
            self.logger.error(f"å°å…­å£¬è§£è¯»å¤±è´¥: {e}")
            return f"ğŸ“ è½å®«ï¼š{result.get('æ—¶è½å®«', 'æœªçŸ¥')}\n\nï¼ˆç³»ç»Ÿç¹å¿™ï¼Œå°†åœ¨åç»­åˆ†æä¸­è¡¥å……è¯¦ç»†è§£è¯»ï¼‰"

    async def _calculate_theory_fitness(self, theory_callback=None) -> str:
        """è®¡ç®—ç†è®ºé€‚é…åº¦"""
        user_input = UserInput(
            question_type=self.context.question_category,
            question_description=self.context.question_description,
            birth_year=self.context.birth_info.get("year") if self.context.birth_info else None,
            birth_month=self.context.birth_info.get("month") if self.context.birth_info else None,
            birth_day=self.context.birth_info.get("day") if self.context.birth_info else None,
            birth_hour=self.context.birth_info.get("hour") if self.context.birth_info else None,
            gender=self.context.gender,
            mbti_type=self.context.mbti_type,
            current_time=datetime.now()
        )
        # ä»é…ç½®è¯»å–ç†è®ºæ•°é‡é™åˆ¶ï¼Œé»˜è®¤max=5, min=3ï¼ˆç¬¦åˆäº§å“å®šä¹‰"3-5ä¸ªç†è®º"ï¼‰
        max_theories = self.config.get("conversation", {}).get("max_theories", DEFAULT_MAX_THEORIES)
        min_theories = self.config.get("conversation", {}).get("min_theories", DEFAULT_MIN_THEORIES)
        selected, _ = self.theory_selector.select_theories(user_input, max_theories=max_theories, min_theories=min_theories)
        self.context.selected_theories = selected

        # æ ¼å¼åŒ–ç†è®ºåˆ—è¡¨ï¼ˆæ”¯æŒå­—å…¸åˆ—è¡¨å’Œå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
        theory_lines = []
        for i, t in enumerate(selected, 1):
            if isinstance(t, dict):
                theory_name = t.get('theory', 'æœªçŸ¥')
                fitness = t.get('fitness', 0)
                info_comp = t.get('info_completeness', 0)
                theory_lines.append(f"{i}. **{theory_name}** (é€‚é…åº¦: {fitness:.0%}, ä¿¡æ¯å®Œå¤‡åº¦: {info_comp:.0%})")
            else:
                theory_lines.append(f"{i}. **{t}**")
        return "\n".join(theory_lines)

    def _adjust_confidence(self, feedback: Dict[str, Any]):
        """è°ƒæ•´ç†è®ºç½®ä¿¡åº¦"""
        # ä½¿ç”¨ accuracy_score å­—æ®µï¼ˆ0-1ä¹‹é—´ï¼‰
        accuracy_score = feedback.get("accuracy_score", 0.5)
        adj = 1.1 if accuracy_score >= 0.8 else (1.0 if accuracy_score >= 0.5 else 0.9)

        for theory_item in self.context.selected_theories:
            # selected_theories å¯èƒ½æ˜¯å­—å…¸åˆ—è¡¨æˆ–å­—ç¬¦ä¸²åˆ—è¡¨
            if isinstance(theory_item, dict):
                theory_name = theory_item.get('theory', str(theory_item))
            else:
                theory_name = str(theory_item)
            self.context.theory_confidence_adjustment[theory_name] = adj

    def _process_theory(
        self,
        theory_name: str,
        user_input: UserInput,
        progress_callback: Optional[Callable] = None,
        theory_callback: Optional[Callable] = None
    ) -> None:
        """
        ç»Ÿä¸€å¤„ç†å•ä¸ªç†è®ºçš„è®¡ç®—æµç¨‹ï¼ˆæ¶ˆé™¤é‡å¤ä»£ç ï¼‰

        Args:
            theory_name: ç†è®ºåç§°
            user_input: ç”¨æˆ·è¾“å…¥
            progress_callback: è¿›åº¦å›è°ƒ
            theory_callback: ç†è®ºçŠ¶æ€å›è°ƒ
        """
        if theory_name not in self.THEORY_CONFIGS:
            self.logger.warning(f"æœªçŸ¥ç†è®º: {theory_name}")
            return

        config = self.THEORY_CONFIGS[theory_name]

        # 1. è¿›åº¦å›è°ƒ
        if progress_callback:
            progress_callback(
                config["progress_name"],
                config["progress_text"],
                config["progress_value"]
            )

        # 2. å¼€å§‹å›è°ƒ
        if theory_callback:
            theory_callback('started', config["display_name"], None)

        # 3. æ‰§è¡Œè®¡ç®—
        try:
            theory_instance = config["theory_class"]()
            result = theory_instance.calculate(user_input)

            # ä¿å­˜ç»“æœåˆ°ä¸Šä¸‹æ–‡
            setattr(self.context, config["context_attr"], result)

            # 4. å®Œæˆå›è°ƒ
            if theory_callback:
                # è·å–summaryå’Œjudgment
                if config.get("has_summary"):
                    summary_method_name = f"_get_{config['context_attr'].replace('_result', '')}_summary"
                    summary = getattr(self, summary_method_name)(result)
                else:
                    summary = config.get("default_summary", "è®¡ç®—å®Œæˆ")

                if config.get("has_judgment"):
                    judgment_method_name = f"_get_{config['context_attr'].replace('_result', '')}_judgment"
                    judgment = getattr(self, judgment_method_name)(result)
                else:
                    judgment = config.get("default_judgment", "å¹³")

                theory_callback('completed', config["display_name"], {
                    'summary': summary,
                    'judgment': judgment
                })

        except Exception as e:
            self.logger.error(f"{theory_name}è®¡ç®—å¤±è´¥: {e}")
            if theory_callback:
                theory_callback('error', config["display_name"], {
                    'error': str(e)
                })

    async def _run_deep_analysis(self, progress_callback, theory_callback=None):
        """æ‰§è¡Œæ·±åº¦åˆ†æï¼ˆé‡æ„ç‰ˆï¼šä½¿ç”¨ç»Ÿä¸€çš„ç†è®ºå¤„ç†å‡½æ•°ï¼‰"""
        if not self.context.birth_info:
            return

        user_input = UserInput(
            question_type=self.context.question_category,
            question_description=self.context.question_description,
            birth_year=self.context.birth_info.get("year"),
            birth_month=self.context.birth_info.get("month"),
            birth_day=self.context.birth_info.get("day"),
            birth_hour=self.context.birth_info.get("hour"),
            gender=self.context.gender,
            mbti_type=self.context.mbti_type,
            current_time=datetime.now()
        )

        # æå–ç†è®ºåç§°åˆ—è¡¨ï¼ˆæ”¯æŒå­—å…¸åˆ—è¡¨å’Œå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
        selected_theory_names = []
        for t in self.context.selected_theories:
            if isinstance(t, dict):
                selected_theory_names.append(t.get('theory', ''))
            else:
                selected_theory_names.append(str(t))

        # ä½¿ç”¨ç»Ÿä¸€æ–¹æ³•å¤„ç†æ‰€æœ‰ç†è®º
        for theory_name in selected_theory_names:
            if theory_name in self.THEORY_CONFIGS:
                self._process_theory(
                    theory_name,
                    user_input,
                    progress_callback,
                    theory_callback
                )

    def _retry_msg(self, stage: str) -> str:
        """ç”Ÿæˆé‡è¯•æç¤ºï¼ˆV2: ä½¿ç”¨FlowGuardæ˜¾ç¤ºè¿›åº¦ï¼‰"""

        # V2: ä½¿ç”¨FlowGuardç”Ÿæˆè¿›åº¦å±•ç¤º
        progress_display = self.flow_guard.generate_progress_display()
        stage_prompt = self.flow_guard.generate_stage_prompt()

        if stage == "stage1":
            return f"""ğŸ˜… æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½å®Œå…¨ç†è§£æ‚¨çš„ä¿¡æ¯ã€‚

{progress_display}

---

{stage_prompt}
"""
        else:
            return f"""ğŸ˜… æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç†è§£æ‚¨çš„å‡ºç”Ÿä¿¡æ¯ã€‚

{progress_display}

---

{stage_prompt}
"""

    # ==================== å·¥å…·æ–¹æ³• ====================

    def save_conversation(self) -> Dict[str, Any]:
        """ä¿å­˜å¯¹è¯å†…å®¹"""
        self.exporter.context = self.context
        return self.exporter.to_save_dict()

    def get_conversation_summary(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯æ‘˜è¦"""
        self.exporter.context = self.context
        return self.exporter.get_summary()

    def get_conversation_statistics(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯"""
        self.exporter.context = self.context
        return self.exporter.get_statistics()

    def get_progress_percentage(self) -> int:
        """è·å–å¯¹è¯è¿›åº¦ç™¾åˆ†æ¯”"""
        progress = {
            ConversationStage.INIT: 0, ConversationStage.STAGE1_ICEBREAK: 20,
            ConversationStage.STAGE2_BASIC_INFO: 40, ConversationStage.STAGE3_SUPPLEMENT: 60,
            ConversationStage.STAGE4_VERIFICATION: 80, ConversationStage.STAGE5_FINAL_REPORT: 95,
            ConversationStage.QA: 100, ConversationStage.COMPLETED: 100
        }
        return progress.get(self.context.stage, 0)

    def reset(self):
        """é‡ç½®å¯¹è¯"""
        self.context = ConversationContext()
        self._init_handlers()
        self.logger.info("å¯¹è¯å·²é‡ç½®")

    def get_current_stage(self) -> str:
        """è·å–å½“å‰å¯¹è¯é˜¶æ®µ"""
        return self.context.stage.value

    def get_stage_description(self) -> str:
        """è·å–å½“å‰é˜¶æ®µæè¿°"""
        desc = {
            ConversationStage.INIT: "å¯¹è¯åˆå§‹åŒ–",
            ConversationStage.STAGE1_ICEBREAK: "é˜¶æ®µ1ï¼šç ´å†° - å¿«é€Ÿäº†è§£æ‚¨çš„é—®é¢˜",
            ConversationStage.STAGE2_BASIC_INFO: "é˜¶æ®µ2ï¼šä¿¡æ¯æ”¶é›† - è·å–å‡ºç”Ÿä¿¡æ¯å’Œç†è®ºé€‚é…åº¦",
            ConversationStage.STAGE3_SUPPLEMENT: "é˜¶æ®µ3ï¼šæ·±åº¦è¡¥å…… - å®Œå–„æ—¶è¾°ç­‰å…³é”®ä¿¡æ¯",
            ConversationStage.STAGE4_VERIFICATION: "é˜¶æ®µ4ï¼šç»“æœç¡®è®¤ - å›æº¯éªŒè¯æé«˜å‡†ç¡®åº¦",
            ConversationStage.STAGE5_FINAL_REPORT: "é˜¶æ®µ5ï¼šç”ŸæˆæŠ¥å‘Š - ç»¼åˆåˆ†æå’Œå»ºè®®",
            ConversationStage.QA: "é—®ç­”äº¤äº’ - éšæ—¶ä¸ºæ‚¨ç­”ç–‘è§£æƒ‘",
            ConversationStage.COMPLETED: "å¯¹è¯å·²å®Œæˆ"
        }
        return desc.get(self.context.stage, "æœªçŸ¥é˜¶æ®µ")

    def export_to_markdown(self) -> str:
        """å°†å¯¹è¯å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
        self.exporter.context = self.context
        return self.exporter.export_to_markdown()

    # ==================== V2: ç†è®ºç»“æœæ‘˜è¦è¾…åŠ©æ–¹æ³• ====================

    def _get_xiaoliu_judgment(self, result: dict) -> str:
        """ä»å°å…­å£¬ç»“æœæå–å‰å‡¶åˆ¤æ–­"""
        if not result:
            return "å¹³"
        gong = result.get('æ—¶è½å®«', '')
        # å¤§å®‰ã€é€Ÿå–œä¸ºå‰ï¼›èµ¤å£ã€å°å‰ä¸ºå¹³ï¼›ç©ºäº¡ã€ç•™è¿ä¸ºå‡¶
        if gong in ('å¤§å®‰', 'é€Ÿå–œ'):
            return "å‰"
        elif gong in ('èµ¤å£', 'ç©ºäº¡', 'ç•™è¿'):
            return "å‡¶"
        return "å¹³"

    def _get_bazi_summary(self, result: dict) -> str:
        """ä»å…«å­—ç»“æœæå–æ‘˜è¦"""
        if not result:
            return "å…«å­—åˆ†æå®Œæˆ"
        day_master = result.get('æ—¥ä¸»', '')
        strength = result.get('ç”¨ç¥åˆ†æ', {}).get('æ—¥ä¸»å¼ºå¼±', '')
        if day_master and strength:
            return f"æ—¥ä¸»{day_master}ï¼Œ{strength}"
        return "å…«å­—å‘½ç›˜å·²æ’å¸ƒ"

    def _get_bazi_judgment(self, result: dict) -> str:
        """ä»å…«å­—ç»“æœæå–å‰å‡¶åˆ¤æ–­"""
        # å…«å­—åˆ†æé€šå¸¸è¾ƒå¤æ‚ï¼Œé»˜è®¤è¿”å›å¹³
        return "å¹³"

    def _get_qimen_summary(self, result: dict) -> str:
        """ä»å¥‡é—¨éç”²ç»“æœæå–æ‘˜è¦"""
        if not result:
            return "å¥‡é—¨å±€èµ·æˆ"
        # å°è¯•æå–å…³é”®ä¿¡æ¯
        if isinstance(result, dict):
            if 'judgment' in result:
                return result['judgment'][:50] if len(result.get('judgment', '')) > 50 else result.get('judgment', 'å¥‡é—¨åˆ†æå®Œæˆ')
        return "å¥‡é—¨å±€èµ·æˆ"

    def _get_qimen_judgment(self, result: dict) -> str:
        """ä»å¥‡é—¨éç”²ç»“æœæå–å‰å‡¶åˆ¤æ–­"""
        if not result:
            return "å¹³"
        # å°è¯•ä»ç»“æœä¸­æå–åˆ¤æ–­
        if isinstance(result, dict):
            judgment_text = result.get('judgment', result.get('åˆ¤æ–­', ''))
            if 'å‰' in judgment_text:
                return "å‰"
            elif 'å‡¶' in judgment_text:
                return "å‡¶"
        return "å¹³"

    def _get_liuyao_summary(self, result: dict) -> str:
        """ä»å…­çˆ»ç»“æœæå–æ‘˜è¦"""
        if not result:
            return "å…­çˆ»å¦èµ·æˆ"
        ben_gua = result.get('æœ¬å¦', {})
        yong_shen = result.get('ç”¨ç¥', {})
        if ben_gua and yong_shen:
            gua_name = ben_gua.get('åç§°', '')
            liu_qin = yong_shen.get('å…­äº²', '')
            return f"{gua_name}ï¼Œç”¨ç¥{liu_qin}"
        return "å…­çˆ»å¦èµ·æˆ"

    def _get_liuyao_judgment(self, result: dict) -> str:
        """ä»å…­çˆ»ç»“æœæå–å‰å‡¶åˆ¤æ–­"""
        if not result:
            return "å¹³"
        judgment = result.get('judgment', '')
        if judgment == 'å‰':
            return "å‰"
        elif judgment == 'å‡¶':
            return "å‡¶"
        return "å¹³"

    def _get_meihua_summary(self, result: dict) -> str:
        """ä»æ¢…èŠ±æ˜“æ•°ç»“æœæå–æ‘˜è¦"""
        if not result:
            return "æ¢…èŠ±å¦èµ·æˆ"
        ben_gua = result.get('æœ¬å¦', {})
        ti_yong = result.get('ä½“ç”¨å…³ç³»', '')
        if ben_gua:
            gua_name = ben_gua.get('åç§°', '')
            return f"{gua_name}ï¼Œ{ti_yong}"
        return "æ¢…èŠ±å¦èµ·æˆ"

    def _get_meihua_judgment(self, result: dict) -> str:
        """ä»æ¢…èŠ±æ˜“æ•°ç»“æœæå–å‰å‡¶åˆ¤æ–­"""
        if not result:
            return "å¹³"
        judgment = result.get('judgment', '')
        if judgment == 'å‰':
            return "å‰"
        elif judgment == 'å‡¶':
            return "å‡¶"
        return "å¹³"

    def can_skip_to_stage(self, target_stage: ConversationStage) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥è·³è½¬åˆ°æŒ‡å®šé˜¶æ®µ"""
        order = [
            ConversationStage.INIT, ConversationStage.STAGE1_ICEBREAK,
            ConversationStage.STAGE2_BASIC_INFO, ConversationStage.STAGE3_SUPPLEMENT,
            ConversationStage.STAGE4_VERIFICATION, ConversationStage.STAGE5_FINAL_REPORT,
            ConversationStage.QA
        ]
        try:
            curr_idx = order.index(self.context.stage)
            tgt_idx = order.index(target_stage)
            if tgt_idx <= curr_idx:
                return False
            if target_stage == ConversationStage.STAGE2_BASIC_INFO:
                return self.context.question_category is not None
            if target_stage in (ConversationStage.STAGE3_SUPPLEMENT, ConversationStage.STAGE4_VERIFICATION):
                return self.context.birth_info is not None
            if target_stage == ConversationStage.STAGE5_FINAL_REPORT:
                return len(self.context.selected_theories) > 0
            if target_stage == ConversationStage.QA:
                return bool(self.context.comprehensive_analysis)
            return True
        except ValueError:
            return False
